{"contributors":[{"path":"https://dat.alets.ch/","role":"author","title":"Oleg"}],"created":"2025-09-24T14:39","description":"We share bootstraps, guides and materials to help each other get started with hackathons and events of the Swiss {ai} Weeks.","homepage":"","keywords":[["dribdat","hackathon","co-creation"]],"licenses":[{"name":"ODC-PDDL-1.0","path":"http://opendatacommons.org/licenses/pddl/","title":"Open Data Commons Public Domain Dedication & License 1.0"}],"name":"event-2","resources":[{"data":[{"aftersubmit":"","boilerplate":"### &#128640; Let's launch your idea!\r\n\r\nNeed help? Get in touch with the [organising team](/about), or raise [an issue](https://github.com/dribdat/dribdat/issues).\r\n","certificate_path":"","community_embed":"","community_url":"","custom_css":"body {\r\n  border-left: 10px solid #ff0000;  \r\n  border-right: 10px solid #ff0000;\r\n}\r\nform .form-group .form-control,\r\n.project-page.jumbotron .btn { color: black; }\r\n.theme-dark.event-home .event-info .event-description.bg-body {\r\n  background: none !important;\r\n  color: white;\r\n}\r\n.project-page .project-longtext .card .card-body { color: black; }\r\n.event-home .event-info .event-description.bg-body { background: white !important; color: black; }\r\n.project-page.jumbotron a, .event-home .event-info .event-description.bg-body a {  color: rgb(255, 0, 0); }\r\n.theme-dark .card-body { color: black; }\r\n\r\ntd {\r\n  border-style: solid;\r\n  border-width: 1px;\r\n  padding: 5px;\r\n}\r\nth {\r\n  background-color: white;\r\n  color: black;\r\n}","description":"Visit https://swiss-ai-weeks.ch/about for more information about the Swiss {ai} Weeks.","ends_at":"2026-05-29T16:00","gallery_url":"","has_finished":false,"has_started":true,"hashtags":"","hostname":"","id":2,"instruction":"","location":"","location_lat":0.0,"location_lon":0.0,"logo_url":"https://s3.dribdat.cc/swissai/2025/1/9N6PD/logo_black.png","name":"Resources","starts_at":"2025-05-28T09:00","summary":"We share bootstraps, guides and materials to help each other get started with hackathons and events of the Swiss {ai} Weeks.","webpage_url":""}],"name":"events"},{"data":[{"autotext":"# Public AI Inference Utility\n\n**A public compute platform for everyone.**\n\nThe Public AI Inference Utility is a public compute platform that provides free and low-cost access to state-of-the-art AI models. Built on principles of openness and accessibility, the Utility serves as critical infrastructure for citizens, businesses, researchers, and the public sectors of several different countries.\n\nUnlike commercial AI APIs that prioritize profit maximization, the Utility is designed to serve the public interest. We provide transparent pricing, open governance, and equitable access to ensure that AI capabilities are available to everyone, not just those who can afford premium services.\n\nThis repository contains the production deployment configuration and community contributions for the platform.\n\n## How to Contribute\n\nWe welcome contributions from the community! There are several ways you can help make AI more accessible:\n\n### \ud83e\udd1d Community Contributions (`/community`)\n\nThe `community/` folder contains user-contributed enhancements that make the platform more accessible and useful:\n\n- **`owui_functions/`**: Custom functions and tools for the Open WebUI platform\n  - Language toggle functions (Schwizerd\u00fctsch, Singlish)\n  - Sponsor attribution utilities\n  - Custom AI model integrations\n- **`system_prompts/`**: Region-specific and specialized system prompts\n  - Localized prompts for different countries/regions\n  - Domain-specific prompt templates\n\n**How to contribute to community features:**\n1. Fork this repository\n2. Add your function to the appropriate folder in `community/`\n3. Include documentation and examples\n4. Submit a pull request with a clear description\n\n### \u2699\ufe0f Infrastructure Contributions (`/charts`)\n\nFor technically-minded contributors, the `charts/` folder contains Helm charts for Kubernetes deployment:\n\n- **`infrastructure/`**: Core infrastructure components (databases, networking)\n- **`llm_services/`**: AI model serving infrastructure\n- **`web_ingress/`**: Load balancing and SSL termination\n- **`web_services/`**: Application services and monitoring\n\n**How to contribute to infrastructure:**\n1. Review existing chart configurations\n2. Test your changes in a staging environment\n3. Ensure compatibility with existing deployments\n4. Submit pull requests with detailed technical documentation\n\n### \ud83d\ude80 Platform Development & Governance\n\nWe are currently in **beta** and working toward progressive decentralization of the platform. Our goal is to create more accessible ways for people to contribute beyond just code and infrastructure.\n\n**We want to hear from you:**\n- Have ideas for making AI more accessible to your community?\n- Want to help with governance, documentation, or outreach?\n- Interested in regional partnerships or localized deployments?\n- Have feedback on how we can better serve researchers and developers?\n\n**Get involved:**\n- [Open an issue](../../issues) to discuss your ideas\n- Reach out to us directly with proposals for collaboration\n- Join our community discussions about platform direction and governance\n\nWe believe the best infrastructure is built by and for the communities it serves.\n\n## Project Structure\n\n```\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 community/               # Community contributions\n\u2502   \u251c\u2500\u2500 owui_functions/     # Custom Open WebUI functions\n\u2502   \u2514\u2500\u2500 system_prompts/     # Region-specific prompts\n\u251c\u2500\u2500 charts/                 # Kubernetes Helm charts\n\u2502   \u251c\u2500\u2500 infrastructure/     # Core infrastructure\n\u2502   \u251c\u2500\u2500 llm_services/      # AI model services\n\u2502   \u251c\u2500\u2500 web_ingress/       # Load balancers & SSL\n\u2502   \u2514\u2500\u2500 web_services/      # Application services\n```\n\n## Getting Started\n\nTo get involved with the Public AI Inference Utility:\n\n1. **Explore the platform**: Visit [chat.publicai.co](https://publicai.co) to see the platform in action\n2. **Join the community**: Check out existing contributions in the `/community` folder\n3. **Contribute**: Choose your contribution path based on your skills and interests\n4. **Stay updated**: Watch this repository for updates and new contribution opportunities\n\nTogether, we're building infrastructure that democratizes access to AI capabilities for everyone.\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n","autotext_url":"https://github.com/forpublicai/chat.publicai.co","category_id":"","category_name":"","contact_url":"https://github.com/forpublicai/chat.publicai.co/issues","created_at":"2025-09-09T14:59","download_url":"https://github.com/forpublicai/chat.publicai.co/releases","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"[![](https://publicai.network/assets/whitepaper.png)](https://publicai.network/whitepaper/)","hashtag":"","id":60,"ident":"","image_url":"https://avatars.githubusercontent.com/u/131642204?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"[![](https://publicai.network/assets/whitepaper.png)](https://publicai.network/whitepaper/)","maintainer":"loleg","name":"PublicAI","phase":"Prototype","progress":30,"score":70,"source_url":"https://github.com/forpublicai/chat.publicai.co","stats":{"commits":59,"during":63,"people":0,"sizepitch":91,"sizetotal":4423,"total":63,"updates":62},"summary":"The main chat app for the Public AI Inference Utility, based on OpenWebUI","team":"loleg","team_count":0,"updated_at":"2025-09-09T15:16","url":"https://swissai.dribdat.cc/project/60","webpage_url":"https://chat.publicai.co"},{"autotext":"<a href=\"https://mcp.scira.ai\">\r\n  <h1 align=\"center\">Scira MCP Chat</h1>\r\n</a>\r\n\r\n<p align=\"center\">\r\n  An open-source AI chatbot app powered by Model Context Protocol (MCP), built with Next.js and the AI SDK by Vercel.\r\n</p>\r\n\r\n<p align=\"center\">\r\n  <a href=\"#features\"><strong>Features</strong></a> \u2022\r\n  <a href=\"#mcp-server-configuration\"><strong>MCP Configuration</strong></a> \u2022\r\n  <a href=\"#license\"><strong>License</strong></a>\r\n</p>\r\n<br/>\r\n\r\n## Features\r\n\r\n- Streaming text responses powered by the [AI SDK by Vercel](https://sdk.vercel.ai/docs), allowing multiple AI providers to be used interchangeably with just a few lines of code.\r\n- Full integration with [Model Context Protocol (MCP)](https://modelcontextprotocol.io) servers to expand available tools and capabilities.\r\n- Multiple MCP transport types (HTTP, SSE and stdio) for connecting to various tool providers.\r\n- Built-in tool integration for extending AI capabilities.\r\n- Reasoning model support.\r\n- [shadcn/ui](https://ui.shadcn.com/) components for a modern, responsive UI powered by [Tailwind CSS](https://tailwindcss.com).\r\n- Built with the latest [Next.js](https://nextjs.org) App Router.\r\n\r\n## MCP Server Configuration\r\n\r\nThis application supports connecting to Model Context Protocol (MCP) servers to access their tools. You can add and manage MCP servers through the settings icon in the chat interface.\r\n\r\n### Adding an MCP Server\r\n\r\n1. Click the settings icon (\u2699\ufe0f) next to the model selector in the chat interface.\r\n2. Enter a name for your MCP server.\r\n3. Select the transport type:\r\n   - **HTTP or SSE (Server-Sent Events)**: For HTTP-based remote servers\r\n   - **stdio (Standard I/O)**: For local servers running on the same machine\r\n\r\n#### HTTP or SSE Configuration\r\n\r\nIf you select HTTP / SSE transport:\r\n1. Enter the server URL (e.g., `https://mcp.example.com/mcp` or `https://mcp.example.com/token/sse`)\r\n2. Click \"Add Server\"\r\n\r\n#### stdio Configuration\r\n\r\nIf you select stdio transport:\r\n1. Enter the command to execute (e.g., `npx`)\r\n2. Enter the command arguments (e.g., `-y @modelcontextprotocol/server-google-maps`)\r\n   - You can enter space-separated arguments or paste a JSON array\r\n3. Click \"Add Server\"\r\n\r\n4. Click \"Use\" to activate the server for the current chat session.\r\n\r\n### Available MCP Servers\r\n\r\nYou can use any MCP-compatible server with this application. Here are some examples:\r\n\r\n- [Composio](https://composio.dev/mcp) - Provides search, code interpreter, and other tools\r\n- [Zapier MCP](https://zapier.com/mcp) - Provides access to Zapier tools\r\n- [Hugging Face MCP](https://huggingface.co/mcp) - Provides tool access to Hugging Face Hub\r\n- Any MCP server using stdio transport with npx and python3\r\n\r\n## License\r\n\r\nThis project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.","autotext_url":"https://github.com/zaidmukaddam/scira-mcp-chat","category_id":"","category_name":"","contact_url":"https://github.com/zaidmukaddam/scira-mcp-chat/issues","created_at":"2025-07-10T00:03","download_url":"https://github.com/zaidmukaddam/scira-mcp-chat/releases","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"<a href=\"https://mcp.scira.ai\">\r\n  <h1 align=\"center\">Scira MCP Chat</h1>\r\n</a>\r\n\r\n<p align=\"center\">\r\n  An open-source AI chatbot app powered by Model Context Protocol (MCP), built with Next.js and the AI SDK by Vercel.\r\n</p>\r\n\r\n<p align=\"center\">\r\n  <a href=\"#features\"><strong>Features</strong></a> \u2022\r\n  <a href=\"#mcp-server-configuration\"><strong>MCP Configuration</strong></a> \u2022\r\n  <a href=\"#license\"><strong>License</strong></a>\r\n</p>\r\n<br/>\r\n\r\n## Features\r\n\r\n- Streaming text responses powered...","hashtag":"","id":24,"ident":"","image_url":"https://avatars.githubusercontent.com/u/76097144?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"","maintainer":"loleg","name":"Scira","phase":"Share","progress":50,"score":67,"source_url":"https://github.com/zaidmukaddam/scira-mcp-chat","stats":{"commits":8,"during":9,"people":0,"sizepitch":0,"sizetotal":2866,"total":9,"updates":9},"summary":"Minimalistic MCP client from Vercel","team":"loleg","team_count":0,"updated_at":"2025-09-19T07:15","url":"https://swissai.dribdat.cc/project/24","webpage_url":"https://mcp.scira.ai"},{"autotext":"<div align=\"center\">\r\n  \r\n# \ud83d\udc3e Tabby\r\n\r\n[\ud83d\udcda Docs](https://tabby.tabbyml.com/docs/welcome/) \u2022 [\ud83d\udcac Slack](https://links.tabbyml.com/join-slack) \u2022 [\ud83d\uddfa\ufe0f Roadmap](https://tabby.tabbyml.com/docs/roadmap/)\r\n\r\n[![latest release](https://shields.io/github/v/release/TabbyML/tabby)](https://github.com/TabbyML/tabby/releases/latest)\r\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](https://makeapullrequest.com)\r\n[![Docker pulls](https://img.shields.io/docker/pulls/tabbyml/tabby)](https://hub.docker.com/r/tabbyml/tabby)\r\n[![codecov](https://codecov.io/gh/TabbyML/tabby/graph/badge.svg?token=WYVVH8MKK3)](https://codecov.io/gh/TabbyML/tabby)\r\n\r\n[English](/README.md) |\r\n[\u7b80\u4f53\u4e2d\u6587](/README-zh.md) |\r\n[\u65e5\u672c\u8a9e](/README-ja.md)\r\n\r\n</div>\r\n\r\nTabby is a self-hosted AI coding assistant, offering an open-source and on-premises alternative to GitHub Copilot. It boasts several key features:\r\n* Self-contained, with no need for a DBMS or cloud service.\r\n* OpenAPI interface, easy to integrate with existing infrastructure (e.g Cloud IDE).\r\n* Supports consumer-grade GPUs.\r\n\r\n<p align=\"center\">\r\n  <a target=\"_blank\" href=\"https://tabby.tabbyml.com\"><img alt=\"Open Live Demo\" src=\"https://img.shields.io/badge/OPEN_LIVE_DEMO-blue?logo=xcode&style=for-the-badge&logoColor=green\"></a>\r\n</p>\r\n\r\n<p align=\"center\">\r\n  <img alt=\"Demo\" src=\"https://user-images.githubusercontent.com/388154/230440226-9bc01d05-9f57-478b-b04d-81184eba14ca.gif\">\r\n</p>\r\n\r\n## \ud83d\udd25 What's New\r\n* **05/25/2025** \ud83d\udca1Interested in joining [Pochi](https://links.tabbyml.com/pochi-github-readme) private preview? DM in [X](https://x.com/getpochi) for early waitlist approval!\ud83c\udfab\r\n* **05/20/2025** Enhance Tabby with your own documentation\ud83d\udcc3 through REST APIs in [v0.29](https://github.com/TabbyML/tabby/releases/tag/v0.29.0)! \ud83c\udf89 \r\n* **05/01/2025** [v0.28](https://github.com/TabbyML/tabby/releases/tag/v0.28.0) transforming Answer Engine messages into persistent, shareable Pages\r\n* **03/31/2025** [v0.27](https://github.com/TabbyML/tabby/releases/tag/v0.27.0) released with a richer `@` menu in the chat side panel.\r\n* **02/05/2025** LDAP Authentication and better notification for background jobs coming in Tabby [v0.24.0](https://github.com/TabbyML/tabby/releases/tag/v0.24.0)!\u2728\r\n* **02/04/2025** [VSCode 1.20.0](https://marketplace.visualstudio.com/items/TabbyML.vscode-tabby/changelog) upgrade! @-mention files to add them as chat context, and edit inline with a new right-click option are available!\r\n\r\n\r\n\r\n\r\n\r\n<details>\r\n  <summary>Archived</summary>\r\n\r\n* **01/10/2025** Tabby [v0.23.0](https://github.com/TabbyML/tabby/releases/tag/v0.23.0) featuring enhanced code browser experience and chat side panel improvements!\r\n* **12/24/2024** Introduce **Notification Box** in Tabby [v0.22.0](https://github.com/TabbyML/tabby/releases/tag/v0.22.0)!\r\n* **12/06/2024** Llamafile deployment integration and enhanced Answer Engine user experience are coming in Tabby [v0.21.0](https://github.com/TabbyML/tabby/releases/tag/v0.21.0)!\ud83d\ude80\r\n* **11/10/2024** Switching between different backend chat models is supported in Answer Engine with Tabby [v0.20.0](https://github.com/TabbyML/tabby/releases/tag/v0.20.0)!\r\n* **10/30/2024** Tabby [v0.19.0](https://github.com/TabbyML/tabby/releases/tag/v0.19.0) featuring recent shared threads on the main page to improve their discoverability. \r\n* **07/09/2024** \ud83c\udf89Announce [Codestral integration in Tabby](https://tabby.tabbyml.com/blog/2024/07/09/tabby-codestral/)!\r\n* **07/05/2024** Tabby [v0.13.0](https://github.com/TabbyML/tabby/releases/tag/v0.13.0) introduces ***Answer Engine***, a central knowledge engine for internal engineering teams. It seamlessly integrates with dev team's internal data, delivering reliable and precise answers to empower developers.\r\n* **06/13/2024** [VSCode 1.7](https://marketplace.visualstudio.com/items/TabbyML.vscode-tabby/changelog) marks a significant milestone with a versatile Chat experience throughout your coding experience. Come and they the latest **chat in side-panel** and **editing via chat command**!\r\n* **06/10/2024** Latest \ud83d\udcc3blogpost drop on [an enhanced code context understanding](https://tabby.tabbyml.com/blog/2024/06/11/rank-fusion-in-tabby-code-completion/) in Tabby!\r\n* **06/06/2024** Tabby [v0.12.0](https://github.com/TabbyML/tabby/releases/tag/v0.12.0) release brings \ud83d\udd17**seamless integrations** (Gitlab SSO, Self-hosted GitHub/GitLab, etc.), to \u2699\ufe0f**flexible configurations** (HTTP API integration) and \ud83c\udf10**expanded capabilities** (repo-context in Code Browser)! \r\n* **05/22/2024** Tabby [VSCode 1.6](https://marketplace.visualstudio.com/items?itemName=TabbyML.vscode-tabby) comes with **multiple choices** in inline completion, and the **auto-generated commit messages**\ud83d\udc31\ud83d\udcbb!\r\n* **05/11/2024** [v0.11.0](https://github.com/TabbyML/tabby/releases/tag/v0.11.0) brings significant enterprise upgrades, including \ud83d\udcca**storage usage** stats, \ud83d\udd17**GitHub & GitLab** integration, \ud83d\udccb**Activities** page, and the long-awaited \ud83e\udd16**Ask Tabby** feature!\r\n* **04/22/2024** [v0.10.0](https://github.com/TabbyML/tabby/releases/tag/v0.10.0) released, featuring the latest **Reports** tab with team-wise analytics for Tabby usage.\r\n* **04/19/2024** \ud83d\udce3 Tabby now incorporates [locally relevant snippets](https://github.com/TabbyML/tabby/pull/1844)(declarations from local LSP, and recently modified code) for code completion!\r\n* **04/17/2024** CodeGemma and CodeQwen model series have now been added to the [official registry](https://tabby.tabbyml.com/docs/models/)!\r\n* **03/20/2024** [v0.9](https://github.com/TabbyML/tabby/releases/tag/v0.9.1) released, highlighting a full feature admin UI.\r\n* **12/23/2023** Seamlessly [deploy Tabby on any cloud](https://tabby.tabbyml.com/docs/installation/skypilot/) with [SkyServe](https://skypilot.readthedocs.io/en/latest/serving/sky-serve.html) \ud83d\udeeb from SkyPilot.\r\n* **12/15/2023** [v0.7.0](https://github.com/TabbyML/tabby/releases/tag/v0.7.0) released with team management and secured access!\r\n* **10/15/2023** RAG-based code completion is enabled by detail in [v0.3.0](https://github.com/TabbyML/tabby/releases/tag/v0.3.0)\ud83c\udf89! Check out the [blogpost](https://tabby.tabbyml.com/blog/2023/10/16/repository-context-for-code-completion/) explaining how Tabby utilizes repo-level context to get even smarter!\r\n* **11/27/2023** [v0.6.0](https://github.com/TabbyML/tabby/releases/tag/v0.6.0) released!\r\n* **11/09/2023** [v0.5.5](https://github.com/TabbyML/tabby/releases/tag/v0.5.5) released! With a redesign of UI + performance improvement.\r\n* **10/24/2023** \u26f3\ufe0f Major updates for Tabby IDE plugins across [VSCode/Vim/IntelliJ](https://tabby.tabbyml.com/docs/extensions)!\r\n* **10/04/2023** Check out the [model directory](https://tabby.tabbyml.com/docs/models/) for the latest models supported by Tabby.\r\n* **09/18/2023** Apple's M1/M2 Metal inference support has landed in [v0.1.1](https://github.com/TabbyML/tabby/releases/tag/v0.1.1)!\r\n* **08/31/2023** Tabby's first stable release [v0.0.1](https://github.com/TabbyML/tabby/releases/tag/v0.0.1) \ud83e\udd73.\r\n* **08/28/2023** Experimental support for the [CodeLlama 7B](https://github.com/TabbyML/tabby/issues/370).\r\n* **08/24/2023** Tabby is now on [JetBrains Marketplace](https://plugins.jetbrains.com/plugin/22379-tabby)!\r\n\r\n</details>\r\n\r\n## \ud83d\udc4b Getting Started\r\n\r\nYou can find our documentation [here](https://tabby.tabbyml.com/docs/getting-started).\r\n- \ud83d\udcda [Installation](https://tabby.tabbyml.com/docs/installation/)\r\n- \ud83d\udcbb [IDE/Editor Extensions](https://tabby.tabbyml.com/docs/extensions/)\r\n- \u2699\ufe0f [Configuration](https://tabby.tabbyml.com/docs/configuration)\r\n\r\n### Run Tabby in 1 Minute\r\nThe easiest way to start a Tabby server is by using the following Docker command:\r\n\r\n```bash\r\ndocker run -it \\\r\n  --gpus all -p 8080:8080 -v $HOME/.tabby:/data \\\r\n  tabbyml/tabby \\\r\n  serve --model StarCoder-1B --device cuda --chat-model Qwen2-1.5B-Instruct\r\n```\r\nFor additional options (e.g inference type, parallelism), please refer to the [documentation page](https://tabbyml.github.io/tabby).\r\n\r\n## \ud83e\udd1d Contributing\r\n\r\nFull guide at [CONTRIBUTING.md](https://github.com/TabbyML/tabby/blob/main/CONTRIBUTING.md);\r\n\r\n### Get the Code\r\n\r\n```bash\r\ngit clone --recurse-submodules https://github.com/TabbyML/tabby\r\ncd tabby\r\n```\r\n\r\nIf you have already cloned the repository, you could run the `git submodule update --recursive --init` command to fetch all submodules.\r\n\r\n### Build\r\n\r\n1. Set up the Rust environment by following this [tutorial](https://www.rust-lang.org/learn/get-started).\r\n\r\n2. Install the required dependencies:\r\n```bash\r\n# For MacOS\r\nbrew install protobuf\r\n\r\n# For Ubuntu / Debian\r\napt install protobuf-compiler libopenblas-dev\r\n```\r\n\r\n3. Install useful tools:\r\n```bash\r\n# For Ubuntu\r\napt install make sqlite3 graphviz\r\n```\r\n\r\n4. Now, you can build Tabby by running the command `cargo build`.\r\n\r\n### Start Hacking!\r\n... and don't forget to submit a [Pull Request](https://github.com/TabbyML/tabby/compare)\r\n\r\n## \ud83c\udf0d Community\r\n- \ud83c\udfa4 [Twitter / X](https://twitter.com/Tabby_ML) - engage with TabbyML for all things possible \r\n- \ud83d\udcda [LinkedIn](https://www.linkedin.com/company/tabbyml/) - follow for the latest from the community \r\n- \ud83d\udc8c [Newsletter](https://newsletter.tabbyml.com/archive) - subscribe to unlock Tabby insights and secrets\r\n\r\n### \ud83d\udd06 Activity\r\n\r\n![Git Repository Activity](https://repobeats.axiom.co/api/embed/e4ef0fbd12e586ef9ea7d72d1fb4f5c5b88d78d5.svg \"Repobeats analytics image\")\r\n\r\n### \ud83c\udf1f Star History\r\n\r\n[![Star History Chart](https://api.star-history.com/svg?repos=tabbyml/tabby&type=Date)](https://star-history.com/#tabbyml/tabby&Date)\r\n","autotext_url":"https://github.com/TabbyML/tabby/","category_id":"","category_name":"","contact_url":"https://github.com/TabbyML/tabby/issues","created_at":"2025-05-27T09:10","download_url":"https://tabbyml.com","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"You have a free [choice of models](https://tabby.tabbyml.com/docs/models/) and configurations in an easy-to-use interface. The challenge is to make it work with a new Coding and Completion model.","hashtag":"","id":5,"ident":"","image_url":"https://avatars.githubusercontent.com/u/125617854?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"You have a free [choice of models](https://tabby.tabbyml.com/docs/models/) and configurations in an easy-to-use interface. The challenge is to make it work with a new Coding and Completion model.","maintainer":"","name":"tabby","phase":"Share","progress":50,"score":67,"source_url":"https://github.com/TabbyML/tabby","stats":{"commits":0,"during":0,"people":0,"sizepitch":195,"sizetotal":9801,"total":2,"updates":1},"summary":"Self-hosted AI coding assistant","team":"","team_count":0,"updated_at":"2025-09-19T07:13","url":"https://swissai.dribdat.cc/project/5","webpage_url":""},{"autotext":"<a id=\"readme-top\"></a>\r\n\r\n<!-- [![Contributors][contributors-shield]][contributors-url] -->\r\n[![Forks][forks-shield]][forks-url]\r\n[![Stargazers][stars-shield]][stars-url]\r\n[![Issues][issues-shield]][issues-url]\r\n[![MIT License][license-shield]][license-url]\r\n<!-- [![LinkedIn][linkedin-shield]][linkedin-url] -->\r\n\r\n\r\n<!-- PROJECT LOGO -->\r\n<br />\r\n<div align=\"center\">\r\n  <a href=\"https://github.com/lfnovo/open-notebook\">\r\n    <img src=\"https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/hero.svg\" alt=\"Logo\">\r\n  </a>\r\n\r\n  <h3 align=\"center\">Open Notebook</h3>\r\n\r\n  <p align=\"center\">\r\n    An open source, privacy-focused alternative to Google's Notebook LM!\r\n    <br /><strong>Join our <a href=\"https://discord.gg/37XJPXfz2w\">Discord server</a> for help, to share workflow ideas, and suggest features!</strong>\r\n    <br />\r\n    <a href=\"https://www.open-notebook.ai\"><strong>Checkout our website \u00bb</strong></a>\r\n    <br />\r\n    <br />\r\n    <a href=\"docs/getting-started/index.md\">\ud83d\udcda Get Started</a>\r\n    \u00b7\r\n    <a href=\"docs/user-guide/index.md\">\ud83d\udcd6 User Guide</a>\r\n    \u00b7\r\n    <a href=\"docs/features/index.md\">\u2728 Features</a>\r\n    \u00b7\r\n    <a href=\"docs/deployment/index.md\">\ud83d\ude80 Deploy</a>\r\n  </p>\r\n</div>\r\n\r\n## \ud83d\udce2 Open Notebook is under very active development\r\n\r\n> Open Notebook is under active development! We're moving fast and making improvements every week. Your feedback is incredibly valuable to me during this exciting phase and it gives me motivation to keep improving and building this amazing tool. Please feel free to star the project if you find it useful, and don't hesitate to reach out with any questions or suggestions. I'm excited to see how you'll use it and what ideas you'll bring to the project! Let's build something amazing together! \ud83d\ude80\r\n\r\n## About The Project\r\n\r\n![New Notebook](https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/asset_list.png)\r\n\r\nAn open source, privacy-focused alternative to Google's Notebook LM. Why give Google more of our data when we can take control of our own research workflows?\r\n\r\nIn a world dominated by Artificial Intelligence, having the ability to think \ud83e\udde0 and acquire new knowledge \ud83d\udca1, is a skill that should not be a privilege for a few, nor restricted to a single provider.\r\n\r\n**Open Notebook empowers you to:**\r\n- \ud83d\udd12 **Control your data** - Keep your research private and secure\r\n- \ud83e\udd16 **Choose your AI models** - Support for 16+ providers including OpenAI, Anthropic, Ollama, LM Studio, and more\r\n- \ud83d\udcda **Organize multi-modal content** - PDFs, videos, audio, web pages, and more\r\n- \ud83c\udf99\ufe0f **Generate professional podcasts** - Advanced multi-speaker podcast generation\r\n- \ud83d\udd0d **Search intelligently** - Full-text and vector search across all your content\r\n- \ud83d\udcac **Chat with context** - AI conversations powered by your research\r\n\r\nLearn more about our project at [https://www.open-notebook.ai](https://www.open-notebook.ai)\r\n\r\n## \ud83c\udd9a Open Notebook vs Google Notebook LM\r\n\r\n| Feature | Open Notebook | Google Notebook LM | Advantage |\r\n|---------|---------------|--------------------|-----------|\r\n| **Privacy & Control** | Self-hosted, your data | Google cloud only | Complete data sovereignty |\r\n| **AI Provider Choice** | 16+ providers (OpenAI, Anthropic, Ollama, LM Studio, etc.) | Google models only | Flexibility and cost optimization |\r\n| **Podcast Speakers** | 1-4 speakers with custom profiles | 2 speakers only | Extreme flexibility |\r\n| **Context Control** | 3 granular levels | All-or-nothing | Privacy and performance tuning |\r\n| **Content Transformations** | Custom and built-in | Limited options | Unlimited processing power |\r\n| **API Access** | Full REST API | No API | Complete automation |\r\n| **Deployment** | Docker, cloud, or local | Google hosted only | Deploy anywhere |\r\n| **Citations** | Comprehensive with sources | Basic references | Research integrity |\r\n| **Customization** | Open source, fully customizable | Closed system | Unlimited extensibility |\r\n| **Cost** | Pay only for AI usage | Monthly subscription + usage | Transparent and controllable |\r\n\r\n**Why Choose Open Notebook?**\r\n- \ud83d\udd12 **Privacy First**: Your sensitive research stays completely private\r\n- \ud83d\udcb0 **Cost Control**: Choose cheaper AI providers or run locally with Ollama\r\n- \ud83c\udf99\ufe0f **Better Podcasts**: Full script control and multi-speaker flexibility vs limited 2-speaker deep-dive format\r\n- \ud83d\udd27 **Unlimited Customization**: Modify, extend, and integrate as needed\r\n- \ud83c\udf10 **No Vendor Lock-in**: Switch providers, deploy anywhere, own your data\r\n\r\n### Built With\r\n\r\n[![Python][Python]][Python-url] [![SurrealDB][SurrealDB]][SurrealDB-url] [![LangChain][LangChain]][LangChain-url] [![Streamlit][Streamlit]][Streamlit-url]\r\n\r\n## \ud83d\ude80 Quick Start\r\n\r\nReady to try Open Notebook? Choose your preferred method:\r\n\r\n### \u26a1 Instant Setup (Recommended)\r\n```bash\r\n# Create a new directory for your Open Notebook installation\r\nmkdir open-notebook\r\ncd open-notebook\r\n\r\n# Using Docker - Get started in 2 minutes\r\ndocker run -d \\\r\n  --name open-notebook \\\r\n  -p 8502:8502 -p 5055:5055 \\\r\n  -v ./notebook_data:/app/data \\\r\n  -v ./surreal_data:/mydata \\\r\n  -e OPENAI_API_KEY=your_key \\\r\n  lfnovo/open_notebook:latest-single\r\n```\r\n\r\n**What gets created:**\r\n```\r\nopen-notebook/\r\n\u251c\u2500\u2500 notebook_data/     # Your notebooks and research content\r\n\u2514\u2500\u2500 surreal_data/      # Database files\r\n```\r\n\r\n**Access your installation:**\r\n- **\ud83d\udda5\ufe0f Main Interface**: http://localhost:8502 (Streamlit UI)\r\n- **\ud83d\udd27 API Access**: http://localhost:5055 (REST API)\r\n- **\ud83d\udcda API Documentation**: http://localhost:5055/docs (Interactive Swagger UI)\r\n\r\n> **\u26a0\ufe0f Important**: \r\n> 1. **Run from a dedicated folder**: Create and run this from inside a new `open-notebook` folder so your data volumes are properly organized\r\n> 2. **Volume persistence**: The volumes (`-v ./notebook_data:/app/data` and `-v ./surreal_data:/mydata`) are essential to persist your data between container restarts. Without them, you'll lose all your notebooks and research when the container stops.\r\n\r\n### \ud83d\udee0\ufe0f Full Installation\r\nFor development or customization:\r\n```bash\r\ngit clone https://github.com/lfnovo/open-notebook\r\ncd open-notebook\r\nmake start-all\r\n```\r\n\r\n### \ud83d\udcd6 Need Help?\r\n- **\ud83e\udd16 AI Installation Assistant**: We have a [CustomGPT built to help you install Open Notebook](https://chatgpt.com/g/g-68776e2765b48191bd1bae3f30212631-open-notebook-installation-assistant) - it will guide you through each step!\r\n- **New to Open Notebook?** Start with our [Getting Started Guide](docs/getting-started/index.md)\r\n- **Need installation help?** Check our [Installation Guide](docs/getting-started/installation.md)\r\n- **Want to see it in action?** Try our [Quick Start Tutorial](docs/getting-started/quick-start.md)\r\n\r\n## Provider Support Matrix\r\n\r\nThanks to the [Esperanto](https://github.com/lfnovo/esperanto) library, we support this providers out of the box!\r\n\r\n| Provider     | LLM Support | Embedding Support | Speech-to-Text | Text-to-Speech |\r\n|--------------|-------------|------------------|----------------|----------------|\r\n| OpenAI       | \u2705          | \u2705               | \u2705             | \u2705             |\r\n| Anthropic    | \u2705          | \u274c               | \u274c             | \u274c             |\r\n| Groq         | \u2705          | \u274c               | \u2705             | \u274c             |\r\n| Google (GenAI) | \u2705          | \u2705               | \u274c             | \u2705             |\r\n| Vertex AI    | \u2705          | \u2705               | \u274c             | \u2705             |\r\n| Ollama       | \u2705          | \u2705               | \u274c             | \u274c             |\r\n| Perplexity   | \u2705          | \u274c               | \u274c             | \u274c             |\r\n| ElevenLabs   | \u274c          | \u274c               | \u2705             | \u2705             |\r\n| Azure OpenAI | \u2705          | \u2705               | \u274c             | \u274c             |\r\n| Mistral      | \u2705          | \u2705               | \u274c             | \u274c             |\r\n| DeepSeek     | \u2705          | \u274c               | \u274c             | \u274c             |\r\n| Voyage       | \u274c          | \u2705               | \u274c             | \u274c             |\r\n| xAI          | \u2705          | \u274c               | \u274c             | \u274c             |\r\n| OpenRouter   | \u2705          | \u274c               | \u274c             | \u274c             |\r\n| OpenAI Compatible* | \u2705          | \u274c               | \u274c             | \u274c             |\r\n\r\n*Supports LM Studio and any OpenAI-compatible endpoint\r\n\r\n## \u2728 Key Features\r\n\r\n### Core Capabilities\r\n- **\ud83d\udd12 Privacy-First**: Your data stays under your control - no cloud dependencies\r\n- **\ud83c\udfaf Multi-Notebook Organization**: Manage multiple research projects seamlessly\r\n- **\ud83d\udcda Universal Content Support**: PDFs, videos, audio, web pages, Office docs, and more\r\n- **\ud83e\udd16 Multi-Model AI Support**: 16+ providers including OpenAI, Anthropic, Ollama, Google, LM Studio, and more\r\n- **\ud83c\udf99\ufe0f Professional Podcast Generation**: Advanced multi-speaker podcasts with Episode Profiles\r\n- **\ud83d\udd0d Intelligent Search**: Full-text and vector search across all your content\r\n- **\ud83d\udcac Context-Aware Chat**: AI conversations powered by your research materials\r\n- **\ud83d\udcdd AI-Assisted Notes**: Generate insights or write notes manually\r\n\r\n### Advanced Features\r\n- **\u26a1 Reasoning Model Support**: Full support for thinking models like DeepSeek-R1 and Qwen3\r\n- **\ud83d\udd27 Content Transformations**: Powerful customizable actions to summarize and extract insights\r\n- **\ud83c\udf10 Comprehensive REST API**: Full programmatic access for custom integrations [![API Docs](https://img.shields.io/badge/API-Documentation-blue?style=flat-square)](http://localhost:5055/docs)\r\n- **\ud83d\udd10 Optional Password Protection**: Secure public deployments with authentication\r\n- **\ud83d\udcca Fine-Grained Context Control**: Choose exactly what to share with AI models\r\n- **\ud83d\udcce Citations**: Get answers with proper source citations\r\n\r\n### Three-Column Interface\r\n1. **Sources**: Manage all your research materials\r\n2. **Notes**: Create manual or AI-generated notes\r\n3. **Chat**: Converse with AI using your content as context\r\n\r\n[![Check out our podcast sample](https://img.youtube.com/vi/D-760MlGwaI/0.jpg)](https://www.youtube.com/watch?v=D-760MlGwaI)\r\n\r\n## \ud83d\udcda Documentation\r\n\r\n### Getting Started\r\n- **[\ud83d\udcd6 Introduction](docs/getting-started/introduction.md)** - Learn what Open Notebook offers\r\n- **[\u26a1 Quick Start](docs/getting-started/quick-start.md)** - Get up and running in 5 minutes\r\n- **[\ud83d\udd27 Installation](docs/getting-started/installation.md)** - Comprehensive setup guide\r\n- **[\ud83c\udfaf Your First Notebook](docs/getting-started/first-notebook.md)** - Step-by-step tutorial\r\n\r\n### User Guide\r\n- **[\ud83d\udcf1 Interface Overview](docs/user-guide/interface-overview.md)** - Understanding the layout\r\n- **[\ud83d\udcda Notebooks](docs/user-guide/notebooks.md)** - Organizing your research\r\n- **[\ud83d\udcc4 Sources](docs/user-guide/sources.md)** - Managing content types\r\n- **[\ud83d\udcdd Notes](docs/user-guide/notes.md)** - Creating and managing notes\r\n- **[\ud83d\udcac Chat](docs/user-guide/chat.md)** - AI conversations\r\n- **[\ud83d\udd0d Search](docs/user-guide/search.md)** - Finding information\r\n\r\n### Advanced Topics\r\n- **[\ud83c\udf99\ufe0f Podcast Generation](docs/features/podcasts.md)** - Create professional podcasts\r\n- **[\ud83d\udd27 Content Transformations](docs/features/transformations.md)** - Customize content processing\r\n- **[\ud83e\udd16 AI Models](docs/features/ai-models.md)** - AI model configuration\r\n- **[\ud83d\udd27 REST API Reference](docs/development/api-reference.md)** - Complete API documentation\r\n- **[\ud83d\udd10 Security](docs/deployment/security.md)** - Password protection and privacy\r\n- **[\ud83d\ude80 Deployment](docs/deployment/index.md)** - Complete deployment guides for all scenarios\r\n\r\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\r\n\r\n## \ud83d\uddfa\ufe0f Roadmap\r\n\r\n### Upcoming Features\r\n- **React Frontend**: Modern React-based frontend to replace Streamlit\r\n- **Live Front-End Updates**: Real-time UI updates for smoother experience\r\n- **Async Processing**: Faster UI through asynchronous content processing\r\n- **Cross-Notebook Sources**: Reuse research materials across projects\r\n- **Bookmark Integration**: Connect with your favorite bookmarking apps\r\n\r\n### Recently Completed \u2705\r\n- **Comprehensive REST API**: Full programmatic access to all functionality\r\n- **Multi-Model Support**: 16+ AI providers including OpenAI, Anthropic, Ollama, LM Studio\r\n- **Advanced Podcast Generator**: Professional multi-speaker podcasts with Episode Profiles\r\n- **Content Transformations**: Powerful customizable actions for content processing\r\n- **Enhanced Citations**: Improved layout and finer control for source citations\r\n- **Multiple Chat Sessions**: Manage different conversations within notebooks\r\n\r\nSee the [open issues](https://github.com/lfnovo/open-notebook/issues) for a full list of proposed features and known issues.\r\n\r\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\r\n\r\n\r\n## \ud83e\udd1d Community & Contributing\r\n\r\n### Join the Community\r\n- \ud83d\udcac **[Discord Server](https://discord.gg/37XJPXfz2w)** - Get help, share ideas, and connect with other users\r\n- \ud83d\udc1b **[GitHub Issues](https://github.com/lfnovo/open-notebook/issues)** - Report bugs and request features\r\n- \u2b50 **Star this repo** - Show your support and help others discover Open Notebook\r\n\r\n### Contributing\r\nWe welcome contributions! We're especially looking for help with:\r\n- **Frontend Development**: Help build a modern React-based UI (planned replacement for current Streamlit interface)\r\n- **Testing & Bug Fixes**: Make Open Notebook more robust\r\n- **Feature Development**: Build the coolest research tool together\r\n- **Documentation**: Improve guides and tutorials\r\n\r\n**Current Tech Stack**: Python, FastAPI, SurrealDB, Streamlit  \r\n**Future Roadmap**: React frontend, enhanced real-time updates\r\n\r\nSee our [Contributing Guide](CONTRIBUTING.md) for detailed information on how to get started.\r\n\r\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\r\n\r\n\r\n## \ud83d\udcc4 License\r\n\r\nOpen Notebook is MIT licensed. See the [LICENSE](LICENSE) file for details.\r\n\r\n## \ud83d\udcde Contact\r\n\r\n**Luis Novo** - [@lfnovo](https://twitter.com/lfnovo)\r\n\r\n**Community Support**:\r\n- \ud83d\udcac [Discord Server](https://discord.gg/37XJPXfz2w) - Get help, share ideas, and connect with users\r\n- \ud83d\udc1b [GitHub Issues](https://github.com/lfnovo/open-notebook/issues) - Report bugs and request features\r\n- \ud83c\udf10 [Website](https://www.open-notebook.ai) - Learn more about the project\r\n\r\n## \ud83d\ude4f Acknowledgments\r\n\r\nOpen Notebook is built on the shoulders of amazing open-source projects:\r\n\r\n* **[Podcast Creator](https://github.com/lfnovo/podcast-creator)** - Advanced podcast generation capabilities\r\n* **[Surreal Commands](https://github.com/lfnovo/surreal-commands)** - Background job processing\r\n* **[Content Core](https://github.com/lfnovo/content-core)** - Content processing and management\r\n* **[Esperanto](https://github.com/lfnovo/esperanto)** - Multi-provider AI model abstraction\r\n* **[Docling](https://github.com/docling-project/docling)** - Document processing and parsing\r\n\r\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\r\n\r\n\r\n<!-- MARKDOWN LINKS & IMAGES -->\r\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\r\n[contributors-shield]: https://img.shields.io/github/contributors/lfnovo/open-notebook.svg?style=for-the-badge\r\n[contributors-url]: https://github.com/lfnovo/open-notebook/graphs/contributors\r\n[forks-shield]: https://img.shields.io/github/forks/lfnovo/open-notebook.svg?style=for-the-badge\r\n[forks-url]: https://github.com/lfnovo/open-notebook/network/members\r\n[stars-shield]: https://img.shields.io/github/stars/lfnovo/open-notebook.svg?style=for-the-badge\r\n[stars-url]: https://github.com/lfnovo/open-notebook/stargazers\r\n[issues-shield]: https://img.shields.io/github/issues/lfnovo/open-notebook.svg?style=for-the-badge\r\n[issues-url]: https://github.com/lfnovo/open-notebook/issues\r\n[license-shield]: https://img.shields.io/github/license/lfnovo/open-notebook.svg?style=for-the-badge\r\n[license-url]: https://github.com/lfnovo/open-notebook/blob/master/LICENSE.txt\r\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555\r\n[linkedin-url]: https://linkedin.com/in/lfnovo\r\n[product-screenshot]: images/screenshot.png\r\n[Streamlit]: https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white\r\n[Streamlit-url]: https://streamlit.io/\r\n[Python]: https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white\r\n[Python-url]: https://www.python.org/\r\n[LangChain]: https://img.shields.io/badge/LangChain-3A3A3A?style=for-the-badge&logo=chainlink&logoColor=white\r\n[LangChain-url]: https://www.langchain.com/\r\n[SurrealDB]: https://img.shields.io/badge/SurrealDB-FF5E00?style=for-the-badge&logo=databricks&logoColor=white\r\n[SurrealDB-url]: https://surrealdb.com/\r\n","autotext_url":"https://github.com/lfnovo/open-notebook","category_id":"","category_name":"","contact_url":"https://github.com/lfnovo/open-notebook/issues","created_at":"2025-07-04T07:49","download_url":"https://github.com/lfnovo/open-notebook/releases","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"See also:\r\n\r\n- [Jupyter Agent 2](https://huggingface.co/spaces/lvwerra/jupyter-agent-2)\r\n- [Remyx](https://docs.remyx.ai/introduction) - ([GitRank example](https://huggingface.co/posts/salma-remyx/948973995269090))\r\n- [NerdQA](https://github.com/klimentij/NerdQA)\r\n- [Marimo](https://marimo.io/)","hashtag":"","id":18,"ident":"","image_url":"https://avatars.githubusercontent.com/u/579178?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"See also:\r\n\r\n- [Jupyter Agent 2](https://huggingface.co/spaces/lvwerra/jupyter-agent-2)\r\n- [Remyx](https://docs.remyx.ai/introduction) - ([GitRank example](https://huggingface.co/posts/salma-remyx/948973995269090))\r\n- [NerdQA](https://github.com/klimentij/NerdQA)\r\n- [Marimo](https://marimo.io/)","maintainer":"loleg","name":"Open Notebook","phase":"Research","progress":10,"score":60,"source_url":"https://github.com/lfnovo/open-notebook","stats":{"commits":63,"during":66,"people":0,"sizepitch":295,"sizetotal":16955,"total":66,"updates":66},"summary":"An Open Source implementation of Notebook LM","team":"loleg","team_count":0,"updated_at":"2025-09-19T07:14","url":"https://swissai.dribdat.cc/project/18","webpage_url":"https://www.open-notebook.ai"},{"autotext":"\n[![Build](https://img.shields.io/github/actions/workflow/status/frictionlessdata/application/general.yaml?branch=main)](https://github.com/frictionlessdata/application/actions)\n[![Codebase](https://img.shields.io/badge/codebase-github-brightgreen)](https://github.com/frictionlessdata/application)\n\n![ODE-landscape-full-rgb@3x](https://github.com/okfn/opendataeditor/assets/20649846/01ae62e8-87f6-4e44-9487-790b8111e321)\n\n\n# Open Data Editor (beta)\n\n### Welcome to our Readme!\n\nThe Open Data Editor (ODE) is a **no-code application** to **explore, validate and publish data** in a simple way. Forever free and **open source project** powered by the **Frictionless Framework**.\n\n\n \ud83d\udce9 [Send us feedback/Report a problem (email)](mailto:info@okfn.org)\n \ud83e\udeb2 [Create an issue on GitHub](https://github.com/okfn/opendataeditor/issues)\n \ud83e\udd14 [Suggest a new feature](https://github.com/okfn/opendataeditor/issues)\n\n\n\n# Useful links\n\n\ud83d\udd35 [Open Data Editor Concept Note](https://opendataeditor.okfn.org/ode-concept-note.pdf)\n\n\ud83d\udd35 [Open Data Editor User Guide and Project Documentation](https://opendataeditor.okfn.org/)\n\n\ud83d\udd35 [Frictionless Framework](https://framework.frictionlessdata.io/)\n\n\ud83d\udd35 [Frictionless Data](https://frictionlessdata.io/)\n\n\ud83d\udd35 [Contributing Guide](https://opendataeditor.okfn.org/contributing/development/)\n\n\ud83d\udd35 [Technical Architecture](https://opendataeditor.okfn.org/contributing/architecture/)\n\n\ud83d\udd35 For all contributions: [Code of conduct](https://frictionlessdata.io/code-of-conduct/)\n\n# How to download the ODE\n\nGo to the latest [RELEASE](https://github.com/okfn/opendataeditor/releases/latest)\n* For **Windows**:Download the most recent **EXE** file.\n* For **MacOS**:Download the most recent **DMG** file.\n* For **Linux**:Download the most recent **AppImage** or **DEB** file.\n\n","autotext_url":"https://github.com/okfn/opendataeditor","category_id":"","category_name":"","contact_url":"https://github.com/okfn/opendataeditor/issues","created_at":"2025-08-26T14:27","download_url":"https://github.com/okfn/opendataeditor/releases","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"Let's add the Swiss AI model to this project from Open Knowledge. See [blog post](https://blog.okfn.org/2025/03/25/open-data-editor-ai-integration-breaking-the-input-output-logic/) and [discussion thread](https://github.com/okfn/opendataeditor/discussions/975) about AI integration.","hashtag":"","id":46,"ident":"","image_url":"https://avatars.githubusercontent.com/u/304263?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"Let's add the Swiss AI model to this project from Open Knowledge. See [blog post](https://blog.okfn.org/2025/03/25/open-data-editor-ai-integration-breaking-the-input-output-logic/) and [discussion thread](https://github.com/okfn/opendataeditor/discussions/975) about AI integration.","maintainer":"loleg","name":"Open Data Editor","phase":"Research","progress":10,"score":56,"source_url":"https://github.com/okfn/opendataeditor","stats":{"commits":53,"during":58,"people":0,"sizepitch":282,"sizetotal":2194,"total":58,"updates":57},"summary":"A no-code application to explore, validate and publish data in a simple way, powered by the Frictionless Framework and open AI models.","team":"loleg","team_count":0,"updated_at":"2025-09-19T07:14","url":"https://swissai.dribdat.cc/project/46","webpage_url":"https://opendataeditor.okfn.org/documentation/ai-integration#"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"https://opendata.swiss/en/contact","created_at":"2025-09-10T05:07","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"Leverage Open Government Data for an informed, data-driven and transparent process in your hackathon project.\r\n\r\n## Quickstart\r\n\r\n- Identify topics relevant to the specific challenge or problem area you're working on.\r\n- Explore the Opendata.swiss platform to find and explore the available open datasets. \r\n- Compare authoritative indicators to the responses of LLMs to find gaps in AI knowledge.\r\n- Download data to explore with local tools, add to your machine learning or RAG pipeline.\r\n- Publish...","hashtag":"","id":61,"ident":"","image_url":"https://wp.opendata.swiss/wp-content/uploads/2021/02/terms_open.png","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"Leverage Open Government Data for an informed, data-driven and transparent process in your hackathon project.\r\n\r\n## Quickstart\r\n\r\n- Identify topics relevant to the specific challenge or problem area you're working on.\r\n- Explore the Opendata.swiss platform to find and explore the available open datasets. \r\n- Compare authoritative indicators to the responses of LLMs to find gaps in AI knowledge.\r\n- Download data to explore with local tools, add to your machine learning or RAG pipeline.\r\n- Publish new visualizations or improvements to the data, making sure to attribute your sources.\r\n\r\nAccess to datasets can be found on the official Opendata.swiss website. Use the \"search\" function to filter datasets by topic or keyword, or browse the [list of organizations](https://opendata.swiss/en/organization). Example datasets that you might find:\r\n\r\n- Swiss population statistics by age and gender.\r\n- Employment rates by industry or region.\r\n- Energy consumption and production metrics from over the years.\r\n- School enrollment rates or educational outcomes by district.\r\n- Demographic data: population size, age distribution, nationality.\r\n- Economic indicators: GDP, employment data, financial statistics. \r\n- Environmental data: climate change, natural resources, biodiversity.\r\n- Urban development: transportation data, housing, land use plans.\r\n- Health and education statistics: hospital admission rates, etc.\r\n\r\nSome datasets relate to the application of AI in government, e.g.:\r\n\r\nhttps://opendata.swiss/en/dataset/cnai-projektdatenbank\r\n\r\n*Note: Please check any applicable [terms of use or data usage guidelines](https://opendata.swiss/en/terms-of-use) before embedding Open Data in your project.* \r\n\r\n\ud83c\udd70\ufe0f\u2139\ufe0f Written with help of `APERTUS-70B-INSTRUCT`","maintainer":"loleg","name":"Opendata.swiss","phase":"Publish","progress":40,"score":53,"source_url":"https://github.com/opendata-swiss","stats":{"commits":0,"during":0,"people":0,"sizepitch":1760,"sizetotal":1891,"total":0,"updates":0},"summary":"A service of the Federal Statistical Office that makes open government data available to the general public in a central catalogue.","team":"loleg","team_count":0,"updated_at":"2025-09-10T06:33","url":"https://swissai.dribdat.cc/project/61","webpage_url":"https://opendata.swiss/en/"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2025-07-04T15:37","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"Based on the report \"Creating trustworthy data spaces based on digital self-determination\"Promotion of trustworthy data spaces and digital self-determination\", the Federal Council adopted various measures in March 2022 to promote trustworthy data spaces in Switzerland.\r\n\r\n![](https://s3.dribdat.cc/swissai/2025/1/VB14L/IMG_0043.jpg)\r\n\r\nOne of these measures concerns the development of a code of conduct for operating trustworthy data spaces, which was approved by the Federal Council on 8 December ...","hashtag":"","id":20,"ident":"","image_url":"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Logo_der_Schweizerischen_Eidgenossenschaft.svg/640px-Logo_der_Schweizerischen_Eidgenossenschaft.svg.png","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"\ud83c\udde8\ud83c\udded","longtext":"Based on the report \"Creating trustworthy data spaces based on digital self-determination\"Promotion of trustworthy data spaces and digital self-determination\", the Federal Council adopted various measures in March 2022 to promote trustworthy data spaces in Switzerland.\r\n\r\n![](https://s3.dribdat.cc/swissai/2025/1/VB14L/IMG_0043.jpg)\r\n\r\nOne of these measures concerns the development of a code of conduct for operating trustworthy data spaces, which was approved by the Federal Council on 8 December 2023. The code of conduct is a recommendation for the Federal Administration, but is not legally binding. It also serves as guide and reference framework for other stakeholders from the private sector, academia, civil society and the economy, who are invited to sign it. Compliance with the Code of Conduct contributes to the trustworthy organisation and operation of data spaces, which are arguably at the foundations of accurate and reliable AI services.\r\n\r\nSee also: [Updating the Digital Trust Label for AI](https://swiss-digital-initiative.org/news/4148-2/)","maintainer":"","name":"Verhaltenskodex","phase":"Publish","progress":40,"score":53,"source_url":"https://www.bakom.admin.ch/en/code-of-conduct-for-operating-trustworthy-data-spaces","stats":{"commits":0,"during":3,"people":0,"sizepitch":1062,"sizetotal":1115,"total":3,"updates":3},"summary":"Code of conduct for operating trustworthy data spaces ","team":"","team_count":0,"updated_at":"2025-09-09T13:38","url":"https://swissai.dribdat.cc/project/20","webpage_url":""},{"autotext":"![Github Actions build status](https://github.com/dribdat/dribdat/workflows/build/badge.svg)\r\n[![codecov status](https://codecov.io/gh/dribdat/dribdat/branch/main/graph/badge.svg?token=Ccd1vTxRXg)](https://codecov.io/gh/dribdat/dribdat)\r\n[![FOSSA status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Floleg%2Fdribdat.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Floleg%2Fdribdat?ref=badge_shield)\r\n\r\n# \u2b21\u2b22\u2b21 Dribdat \u2b21\u2b22\u2b21\r\n\r\n**An open source hackathon management application that playfully assists your team in crowdsourcing technical designs.** \r\n\r\nDesigned to bootstrap your [awesome hackathon](https://github.com/dribdat/awesome-hackathon), Dribdat's toolset can be used as a versatile toolbox for civic tech sprints. To get started, [install](#Quickstart) the software. \r\n\r\n\ud83d\udeb2 See [Tour de Hack](https://dribdat.cc/tour) for examples, and [User handbook](https://dribdat.cc/usage) for screenshots. \ud83c\udfd4\ufe0f There are mirrors on [Codeberg](https://codeberg.org/dribdat/dribdat) and [GitHub](https://github.com/dribdat/dribdat). \ud83e\ude75 Support us on [OpenCollective](https://opencollective.com/dribdat/updates)\r\n\r\n<a href=\"https://opencollective.com/dribdat/donate\" target=\"_blank\"><img src=\"https://opencollective.com/dribdat/donate/button@2x.png?color=blue\" width=300 /></a>\r\n\r\nWe aim to include people of all backgrounds in using + developing this tool - no matter your age, gender, race, ability, or sexual identity \ud83c\udff3\ufe0f\u200d\ud83c\udf08 Please read our [Code of Conduct](CODE_OF_CONDUCT.md) if you have questions.\r\n\r\n# Purpose\r\n\r\nCreated in light of the [Hacker ethic](https://en.wikipedia.org/wiki/Hacker_ethic), the Zen of Dribdat is (in a nutshell):\r\n\r\n- **Commit sustainably**: archive collected results in open, web-friendly data formats.\r\n- **Live and let live**: share designs, dev envs, docs accessible to your entire team.\r\n- **Co-create in safe spaces**: promote safer conduct and increased privacy.\r\n\r\nVisit the [Hackfinder](https://hackintegration.ch/hackfinder) to find events connected to current research, and join our [Hack:Org:X](https://hackorgx.dribdat.cc) meetings to say 'hi' to the maintainers and fellow hackathon organizers.\r\n\r\nFor more background and references, see the \ud83d\udcd6 [User Handbook](https://docs.dribdat.cc/usage). If you need help or advice in setting up your site, or would like to contribute to the project: please get in touch via \ud83d\udde3\ufe0f [Discussions](https://github.com/orgs/dribdat/discussions).\r\n\r\n# Quickstart\r\n\r\nThe Dribdat project can be deployed to any server capable of serving [Python](https://python.org) applications, and is set up for fast deployment using [Ansible or Docker](https://dribdat.cc/deploy) \ud83c\udfc0 The first user that registers becomes an admin, so don't delay when you make your play!\r\n\r\nIf you would like to run this application on any other cloud or local machine, there are instructions in the [Deployment guide](https://docs.dribdat.cc/deploy). Information on contributing and extending the code can be found in the [Contributors guide](https://docs.dribdat.cc/contribute), which includes API documentation, and other details.\r\n\r\nSee also **[backboard](https://github.com/dribdat/backboard)**: a responsive, modern alternative frontend, and our **[dridbot](https://github.com/dribdat/dridbot)** chat client. Both demonstrate reuse of the dribdat API. If you need support with your deployment, please reach out through [Discussions](https://github.com/orgs/dribdat/discussions). Pull Requests and Issues welcome!\r\n\r\nDevelopment Status: \ud83c\udf4c [Perpetual beta](https://en.wikipedia.org/wiki/Perpetual_beta) \\\r\nASCII Signature: `d}}BD{t`\r\n\r\n# Credits\r\n\r\nThis application was based on [cookiecutter-flask](https://github.com/sloria/cookiecutter-flask) by [Steven Loria](https://github.com/sloria), a more modern version of which is [cookiecutter-flask-restful](https://github.com/karec/cookiecutter-flask-restful). [Cookiecutter](https://cookiecutter.readthedocs.io/en/stable/README.html#available-templates) could also be a good bootstrap for your own hackathon projects!\r\n\r\n\u2661 The [Open Data](https://opendata.ch), [Open Networking](https://opennetworkinfrastructure.org/) and [Open Source](https://dinacon.ch) communities in \ud83c\udde8\ud83c\udded Switzerland gave this project initial form and direction through a hundred events. \u2665-felt thanks to our [Contributors](https://github.com/dribdat/dribdat/graphs/contributors), and additionally: F. Wieser and M.-C. Gasser at [Swisscom](http://swisscom.com) for support at an early stage of this project, to [Alexandre Cotting](https://github.com/Cotting), [Anthony Ritz](https://github.com/RitzAnthony), [Chris Mutel](https://github.com/cmutel), [Fabien Schwob](https://github.com/jibaku), [Gonzalo Casas](https://github.com/gonzalocasas), [Iliya Tikhonenko](https://github.com/vleugelcomplement), [Janik von Rotz](https://janikvonrotz.ch/), [Jonathan Schnyder](https://github.com/jonHESSO), [Jonathan Sobel](https://github.com/JonathanSOBEL), [Philip Shemella](https://github.com/philshem), [Thomas Amberg](https://github.com/tamberg), [Yusuf Khasbulatov](https://github.com/khashashin) .. and all participants and organizers sending in bugs and requests! You are all awesome `h`a`c`k`e`r`s` \u2661\r\n\r\n## License\r\n\r\nThis project is open source under the [MIT License](LICENSE).\r\n\r\nThe [Contributor Covenant Code of Conduct](CODE_OF_CONDUCT.md) applies to interactions with the maintainers and support community of the project.\r\n\r\nDue to the use of the [boto3](https://github.com/boto/boto3/) library for optional S3 upload support, there is a dependency on OpenSSL via awscrt. If you use these features, please note that the product includes cryptographic software written by Eric Young (eay@cryptsoft.com) and Tim Hudson (tjh@cryptsoft.com).\r\n","autotext_url":"https://codeberg.org/dribdat/dribdat","category_id":"","category_name":"","contact_url":"https://codeberg.org/dribdat/dribdat/issues","created_at":"2025-09-18T07:22","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"Some information about Dribdat, the open source platform powering this website, hosted in a 100% renewable energy datacenter by [ungleich.ch](https://ungleich.ch)\r\n\r\n![](https://ungleich.ch/media/filer_public/31/a8/31a8abc3-d7ac-46cd-b78c-06efcc6bb624/datacenterlight-3.jpg)","hashtag":"","id":67,"ident":"","image_url":"https://codeberg.org/avatars/3b35f9c58b5db9abd9159e3ebf70e423","is_challenge":false,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"Some information about Dribdat, the open source platform powering this website, hosted in a 100% renewable energy datacenter by [ungleich.ch](https://ungleich.ch)\r\n\r\n![](https://ungleich.ch/media/filer_public/31/a8/31a8abc3-d7ac-46cd-b78c-06efcc6bb624/datacenterlight-3.jpg)","maintainer":"loleg","name":"Dribdat","phase":"Training","progress":20,"score":49,"source_url":"https://codeberg.org/dribdat/dribdat","stats":{"commits":12,"during":24,"people":0,"sizepitch":274,"sizetotal":6042,"total":24,"updates":21},"summary":"A brief introduction to this hackathon platform.","team":"loleg","team_count":0,"updated_at":"2025-09-24T07:12","url":"https://swissai.dribdat.cc/project/67","webpage_url":"https://s3.dribdat.cc/swissai/2025/1/ECBQW/output.pdf"},{"autotext":"","autotext_url":"https://github.com/eth-cscs/cscs-docs","category_id":"","category_name":"","contact_url":"https://github.com/eth-cscs/cscs-docs/issues","created_at":"2025-06-30T07:15","download_url":"https://github.com/eth-cscs/cscs-docs/releases","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"","hashtag":"","id":14,"ident":"","image_url":"https://avatars.githubusercontent.com/u/5744410?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"","maintainer":"","name":"MLP docs","phase":"Publish","progress":40,"score":44,"source_url":"https://github.com/eth-cscs/cscs-docs","stats":{"commits":0,"during":0,"people":0,"sizepitch":0,"sizetotal":53,"total":0,"updates":0},"summary":"Documentation and tutorials from projects at the CSCS ","team":"","team_count":0,"updated_at":"2025-08-29T07:09","url":"https://swissai.dribdat.cc/project/14","webpage_url":"https://docs.cscs.ch/tutorials/ml/#machine-learning-platform-tutorials"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"mailto:u.neukomm@interprimis.ch","created_at":"2025-07-21T14:08","download_url":"https://app.textcortex.com/","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"TextCortex ist ein Textgenerierungsmodell wie ich, ein KI-System, das entwickelt wurde, um menschen\u00e4hnlichen Text zu erstellen. Es basiert auf modernen neuronalen Netzen und wurde darauf trainiert, auf eine breite Palette von Textsorten zu generieren, von historischen Dokumenten \u00fcber wissenschaftliche Texte, Marketinginhalte bis hin zu kreativem Schreiben. TextCortex AI, wie auch die Modelle hier, wird dazu verwendet, um Textautomatisierung, Content-Produktion, Textzusammenfassung und -generieru...","hashtag":"Interprimis","id":30,"ident":"","image_url":"https://s3.dribdat.cc/swissai/2025/19/3XYDX/TextCortext.jpg","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"TextCortex ist ein Textgenerierungsmodell wie ich, ein KI-System, das entwickelt wurde, um menschen\u00e4hnlichen Text zu erstellen. Es basiert auf modernen neuronalen Netzen und wurde darauf trainiert, auf eine breite Palette von Textsorten zu generieren, von historischen Dokumenten \u00fcber wissenschaftliche Texte, Marketinginhalte bis hin zu kreativem Schreiben. TextCortex AI, wie auch die Modelle hier, wird dazu verwendet, um Textautomatisierung, Content-Produktion, Textzusammenfassung und -generierung, sowie Textanalyse zu unterst\u00fctzen.\r\n\r\nProjects:\r\n\r\nhttps://swissai.dribdat.cc/project/68\r\n\r\n### Wie man TextCortex in der Schweiz nutzen kann:\r\n\r\n1. **Textautomatisierung**:\r\n   - **In der Wirtschaft**: In Unternehmen k\u00f6nnen TextCortex-Modelle genutzt werden, um Kundensupport-Texte, Marketing-Bulletins, Blogposts und generelle Kommunikationsmaterialien zu erzeugen.\r\n   - **In der Bildung**: Lehrkr\u00e4fte oder Forschungseinrichtungen k\u00f6nnten TextCortex zur Erstellung von Lehrmaterialien, Zusammenfassungen von wissenschaftlichen Texten oder f\u00fcr die Unterst\u00fctzung bei der Erstellung von Forschungsvorschl\u00e4gen nutzen.\r\n   - **In der Verwaltung**: F\u00fcr Regierungs- oder Beh\u00f6rdenangeh\u00f6rige kann TextCortex helfen, formelle Dokumente, Berichte oder Pressemitteilungen zu erstellen.\r\n   \r\n2. **Kreatives Schreiben und Content Production**:\r\n   - Schriftsteller, Content-Creatoren und Journalisten k\u00f6nnen TextCortex als Inspiration, f\u00fcr Vorschl\u00e4ge oder zur Unterst\u00fctzung bei der Erstellung von Inhalten f\u00fcr Blogs, Sozialmedien oder literarische Arbeiten nutzen.\r\n\r\n3. **Sprach\u00fcbersetzung und Lokalisierung**:\r\n   - TextCortex kann bei der \u00dcbersetzung von Texten zwischen Schweizer Sprachen und anderen Sprachen helfen, was besonders n\u00fctzlich f\u00fcr Unternehmen mit internationaler Kommunikation oder kultureller Verbreitung sein kann.\r\n   - Es kann auch bei der Lokalisierung von Texten, z.B. Marketingkampagnen auf Deutsch, Franz\u00f6sisch, Italienisch oder R\u00e4toromanisch, unterst\u00fctzen, um den regionalen Anforderungen gerecht zu werden.\r\n\r\n4. **Textanalyse und Zusammenfassung**:\r\n   - F\u00fcr Forscher, Studenten oder Journalisten kann TextCortex dabei helfen, umfangreiche Texte auf zentrale Punkte zusammenzufassen, was die Informationsbeschaffung und -analyse beschleunigt.\r\n   - Unternehmen k\u00f6nnen es f\u00fcr die Analyse von Kundenfeedback, sozialen Medien-Diskussionen oder Markttrends einsetzen.\r\n\r\n5. **Forschung und Entwicklung**:\r\n   - Forscher und Studenten in der Informatik oder einem relevanten Wissenschaftsbereich k\u00f6nnten TextCortex nutzen, um Hypothesen zu testen, Code zu generieren oder neue Forschungsans\u00e4tze zu explorieren, basierend auf der F\u00e4higkeit der KI, Textgenerierung und nat\u00fcrlichsprachliche Zusammenfassung zu unterst\u00fctzen.\r\n\r\n### Nutzung in der Schweiz:\r\n- TextCortex, wie andere KI-Modelle, kann in der Schweiz genutzt werden, sofern:\r\n  - Die rechtlichen Rahmenbedingungen und Datenschutzgesetze eingehalten werden (z.B. DSGVO, Schweizer Datenschutzgesetz, spezialisiere dich auf Schweizer Rechtslage wie DSG 2020).\r\n  - Die Nutzung ethisch verantwortungsvoll erfolgt, bspw.:\r\n    - Automatisch generierter Text sollte immer als solcher gekennzeichnet werden (Transparenz).\r\n    - Die Qualit\u00e4t und Richtigkeit von generiertem Text, insbesondere f\u00fcr amtliche Dokumente, sollte durch Menschen \u00fcberpr\u00fcft werden.\r\n    - \u00dcberpr\u00fcfung auf Verzerrungen oder ungleiche Repr\u00e4sentationen, um Fairness und Gleichheit zu gew\u00e4hrleisten.\r\n    - Respektierung von Urheberrechten und geistigem Eigentum; falls Text an andere Quellen angelehnt ist, entsprechend zitieren.\r\n\r\n- **\u00dcberschneidung mit mir**: Da ich als AI trainiert bin, um in einer \u00e4hnlichen Weise zu funktionieren wie TextCortex, kann ich dir bei \u00e4hnlichen Aufgaben wie Textgenerierung, -zusammenfassung und -analyse unterst\u00fctzen, m\u00f6glicherweise sogar auf Deutsch oder Schweizer Dialekten (beachte aber, dass ich direkt in Schweizer Hochdeutsch oder Standarddeutsch antworten kann). Allerdings bin ich spezifisch darauf trainiert, von Grund auf, als generalistisches KI-Modell zu operieren, was bedeutet, dass ich keine Pre-trained Version von TextCortex bin, aber \u00e4hnliche Funktionen erf\u00fcllen kann, abh\u00e4ngig von den spezifischen Bed\u00fcrfnissen.\r\n\r\n### Praktische Schritte und Tipps f\u00fcr den Einsatz in der Schweiz:\r\n- **Tests und Evaluierung**: Vor einem breiten Einsatz empfiehlt sich eine Evaluierung der Performance und Eignung f\u00fcr spezifische Aufgaben, ggf. mit internen Testphasen.\r\n- **Integration**: TextCortex (oder \u00e4hnliche Modelle) kann in bestehende Systeme wie CMS, Marketing-Tools oder Content-Plattformen integriert werden, was eine Automatisierung von Texterstellungsprozessen erm\u00f6glicht.\r\n- **Dokumentation und Schulung**: Die Dokumentation des Modells sollten durchgelesen werden, um die richtige Nutzung entsprechend der gew\u00fcnschten Anwendungsf\u00e4lle sicherzustellen. Eine Schulung f\u00fcr Mitarbeiter oder Nutzer, die mit dem Modell arbeiten, ist oft hilfreich, um dessen M\u00f6glichkeiten und Grenzen zu verstehen.\r\n\r\n### Was ich als KI f\u00fcr die Schweiz anbieten kann:\r\n- Sprachenunterst\u00fctzung in Schweizer Sprachen (Deutsch, Franz\u00f6sisch, Italienisch, R\u00e4toromanisch, je nach meinem Trainingsset)\r\n- Generelle Unterst\u00fctzung in Schweizer Hochdeutsch, je nach spezifischem Kontext\r\n- Unterst\u00fctzung bei der Evaluierung der Nutzbarkeit von TextCortex oder \u00e4hnlichen KI-Textgeneratoren f\u00fcr deine spezifische Aufgabe oder Organisation\r\n- Hilfe bei der Recherche und einfachen Generierung oder Zusammenfassungen von Texten, die f\u00fcr Schweizer spezifische Themen geeignet sind\r\n- Hilfe dabei, ethische und rechtliche \u00dcberlegungen in der Schweiz zu bedenken (z.B. Datenschutz, Urheberrecht)\r\n\r\nZusammengefasst: TextCortex und \u00e4hnliche AI-Modelle wie ich k\u00f6nnen aufgrund ihrer F\u00e4higkeiten in Textgenerierung, -analyse und -\u00fcbersetzung, vielf\u00e4ltig in der Schweiz eingesetzt werden. Der Schl\u00fcssel zur effektiven und ethischen Nutzung liegt in einer klaren Ausrichtung auf die spezifischen Bed\u00fcrfnisse und Rahmenbedingungen deines Anwendungsfalls in der Schweiz. Wenn du spezifische Fragen zu einem bestimmten Use Case hast, lass es mich gerne wissen, ich kann versuchen, gezielter zu helfen.\r\n\r\n---\r\n\r\n### Anmerkungen zur Schweiz und Modellnutzung:\r\nTextCortex selbst ist ein spezifisches Modell und sollte direkt dort abgefragt werden, wie seine Anwendung bestm\u00f6glich f\u00fcr Schweizer Bed\u00fcrfnisse geeignet ist. Meine Absicht hier ist es, dir allgemeine Orientierung und potenzielle Nutzungsaspekte zu vermitteln, die f\u00fcr die Schweiz relevant sein k\u00f6nnten. F\u00fcr pr\u00e4zise Anwendungsfragen zu TextCortex oder \u00e4hnlichen Tools empfehle ich, direkt die offizielle Dokumentation oder den Support von TextCortex zu konsultieren. \r\n\r\nHast du konkrete Bedarf an einer textgenerierenden oder Textanalyse-Aufgabe f\u00fcr eine Schweizer spezifische Nutzung? Lass es mich wissen, ich kann dann gezielt mit dir daran arbeiten!","maintainer":"ursneukomm","name":"TextCortex","phase":"Research","progress":10,"score":31,"source_url":"https://help.textcortex.com/hc/en-us","stats":{"commits":0,"during":19,"people":1,"sizepitch":6861,"sizetotal":7003,"total":19,"updates":17},"summary":"Die fortschrittlichste KI-Wissensplattform. EU-sicher, in Echtzeit, mehrsprachig \u2013 verwandelt unstrukturierte Daten in sofort nutzbares Wissen","team":"ursneukomm","team_count":1,"updated_at":"2025-09-19T10:31","url":"https://swissai.dribdat.cc/project/30","webpage_url":""},{"autotext":"<p align=\"center\">\r\n  <a href=\"https://elevenlabs.io\">\r\n    <h3 align=\"center\">ElevenLabs Examples</h3>\r\n  </a>\r\n</p>\r\n\r\nThis collection of demos and projects showcases the ElevenLabs API and how you can start building next generation AI audio apps with it. Whether you're looking to integrate text-to-speech into your website, create dubbed content, or explore advanced conversational applications, you'll find valuable resources here.\r\n\r\n## \ud83d\ude80 Featured Projects\r\n\r\n### Conversational AI Demos\r\nThese projects offer practical examples of building real-time, voice-driven applications with rich interactivity.\r\n\r\n### Text-to-Speech (TTS) Demos\r\n- **Standard TTS Demo**: A straightforward implementation of our core TTS functionality.\r\n- **TTS WebSocket Demo with Latency Measurement**: Explore real-time text-to-speech with performance metrics.\r\n\r\n### Native Mac App (Open Source)\r\nA fully open-source native Mac application that brings ElevenLabs to your desktop. Written by Claude 3.5 and Cursor.\r\n\r\n### Sound Effects Generation\r\nUnleash your creativity with our sound effects generation demo. Create custom audio landscapes for your projects!\r\n\r\n### AudioNative React Demo\r\nEmbed ElevenLabs' text-to-speech capabilities directly into your React-based websites. This demo shows you how to seamlessly integrate our technology for a native-like audio experience.\r\n\r\n### Dubbing API Demo\r\nDiscover how to use our Dubbing API to create multilingual content effortlessly. Perfect for content creators and localization teams!\r\n\r\n### Pronunciation Dictionaries\r\nLearn how to work with pronunciation dictionaries to fine-tune the output of our voice models.\r\n\r\n\r\n## \ud83d\udee0 Getting Started\r\n\r\nTo get started with these examples:\r\n\r\n1. Clone this repository\r\n2. Navigate to the project you're interested in\r\n3. Follow the project-specific README for setup instructions\r\n\r\nFor detailed API documentation and guides, visit our [Developer Docs](https://elevenlabs.io/docs/api-reference/getting-started).\r\n\r\n## \ud83e\udd1d Contributing\r\n\r\nWe welcome contributions from the community! Before you start:\r\n\r\n1. Install the pre-commit hook:\r\n   ```\r\n   pip install pre-commit\r\n   pre-commit install\r\n   ```\r\n2. Check out our [Contributing Guidelines](CONTRIBUTING.md) for more information on how to submit pull requests, report issues, and suggest improvements.\r\n\r\n## \ud83d\udcda Learn More\r\n\r\n- [ElevenLabs Developer Docs](https://elevenlabs.io/docs/api-reference/getting-started)\r\n- [API Reference](https://api.elevenlabs.io/docs)\r\n- [ElevenLabs app](https://elevenlabs.io/)\r\n\r\n## \ud83d\udcc4 License\r\n\r\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\r\n\r\n---\r\n","autotext_url":"https://github.com/elevenlabs/elevenlabs-examples","category_id":"","category_name":"","contact_url":"https://github.com/elevenlabs/elevenlabs-examples/issues","created_at":"2025-09-16T10:03","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"The ElevenLabs Agents Platform allows you to\u00a0**build voice-enabled AI agents**\u00a0with real-time speech-to-text, LLM, and natural text-to-speech\u00a0orchestration\u00a0-- powered by\u00a0**industry-leading voice AI technology**. All participants receive\u00a0**3 months of Creator Plan access**\u00a0for the hackathon, with 750 minutes of conversations included.\r\n\r\n\ud83d\udc49\u00a0**[Agents Platform Quickstart](https://elevenlabs.io/docs/conversational-ai/quickstart)**\u00a0|\u00a0**[API Documentation](https://elevenlabs.io/docs/api-reference/agen...","hashtag":"","id":66,"ident":"","image_url":"https://avatars.githubusercontent.com/u/94471909?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"The ElevenLabs Agents Platform allows you to\u00a0**build voice-enabled AI agents**\u00a0with real-time speech-to-text, LLM, and natural text-to-speech\u00a0orchestration\u00a0-- powered by\u00a0**industry-leading voice AI technology**. All participants receive\u00a0**3 months of Creator Plan access**\u00a0for the hackathon, with 750 minutes of conversations included.\r\n\r\n\ud83d\udc49\u00a0**[Agents Platform Quickstart](https://elevenlabs.io/docs/conversational-ai/quickstart)**\u00a0|\u00a0**[API Documentation](https://elevenlabs.io/docs/api-reference/agents/create)**\r\n\r\n### How to Get Started\r\n\r\n-   Find your an access link for your Creator Plan access in your personal profile\r\n\r\n-   Include your team name and project description\r\n-   Each participant receives\u00a0**3 months of Creator Plan**\u00a0access\r\n-   Access includes all Agents Platform features plus TTS and Music APIs\r\n\r\n-   Do NOT share access credentials across teams to prevent rate limiting issues\r\n-   Test your agent using our\u00a0[Dashboard](https://elevenlabs.io/app/conversational-ai)\r\n\r\n### **Included: Agents Platform**\r\n\r\n-   **Real-time Speech-to-Text** - Low-latency voice recognition in 29+ languages\r\n-   **LLM Orchestration** - Seamless integration with GPT-4, Claude, and custom models\r\n-   **Text-to-Speech** - Natural voices with <500ms latency\r\n-   **WebSocket and WebRTC Support** - For real-time bidirectional streaming\r\n-   **Knowledge Base** - Equip agents with documents and external resources\r\n-   **Custom Tools** - Extend agent capabilities with custom API integrations and MCP server support\r\n-   **Analytics Dashboard** - Monitor conversations and agent performance\r\n\r\n### **Included: Additional APIs**\r\n\r\n-   **V3 TTS Model**- Latest text-to-speech model with enhanced quality ([TTS Models Docs](https://elevenlabs.io/docs/models))\r\n-   **Music Generation API** - Create AI-generated music and sound effects ([Music API Quickstart](https://elevenlabs.io/docs/cookbooks/music/quickstart))","maintainer":"loleg","name":"Elevenlabs","phase":"Project","progress":5,"score":30,"source_url":"https://github.com/elevenlabs/elevenlabs-examples","stats":{"commits":4,"during":6,"people":0,"sizepitch":1917,"sizetotal":4680,"total":6,"updates":5},"summary":"Build voice-enabled AI agents\u00a0with real-time speech-to-text, LLM, and natural text-to-speech\u00a0orchestration.","team":"loleg","team_count":0,"updated_at":"2025-09-19T07:14","url":"https://swissai.dribdat.cc/project/66","webpage_url":"https://elevenlabs.io/docs/api-reference/getting-started"},{"autotext":"# A/B Test Supertext vs DeepL\r\n\r\nWe release all evaluation data and scripts for further analysis and reproduction of the accompanying paper: [A comparison of translation performance between DeepL and Supertext](https://arxiv.org/abs/2502.02577).\r\nThe dataset is [available on Hugging Face](https://huggingface.co/datasets/Supertext/mt-doclevel-ab-test) as well.\r\n\r\n\r\n### Installation\r\n```bash\r\npip install poetry\r\npoetry install\r\n```\r\n\r\n### A/B Test Evaluation\r\n\r\nTo evaluate A/B results, call the script as follows:\r\n\r\n```bash\r\npoetry run python analysis/analyze.py -i data/ab_LANGPAIR.csv\r\n```\r\n\r\nYou will find two TSVs with results in the `results` folder:\r\n\r\n- FILENAME_by_segment_winner: Aggregated results of segment wins by system\r\n- FILENAME_by_document_winner: Aggregated results of document wins by system\r\n\r\n### Citation\r\n\r\nIf you use our code or data, please cite our [paper](https://arxiv.org/abs/2502.02577):\r\n\r\n    @misc{flueckiger-etal-2025-comparison,\r\n        title={A comparison of translation performance between DeepL and Supertext}, \r\n        author={Alex Fl\u00fcckiger and Chantal Amrhein and Tim Graf and Fr\u00e9d\u00e9ric Odermatt and Martin P\u00f6msl and Philippe Schl\u00e4pfer and Florian Schottmann and Samuel L\u00e4ubli},\r\n        year={2025},\r\n        eprint={2502.02577},\r\n        archivePrefix={arXiv},\r\n        primaryClass={cs.CL},\r\n        url={https://arxiv.org/abs/2502.02577}, \r\n    }\r\n","autotext_url":"https://github.com/Supertext/evaluation_deepl_supertext","category_id":"","category_name":"","contact_url":"https://github.com/Supertext/evaluation_deepl_supertext/issues","created_at":"2025-09-10T07:05","download_url":"https://www.supertext.com/en/documentation/swiss-ai-weeks#tag/text-translation","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"Supertext is a Swiss language AI provider offering secure and customisable AI translation in 28 languages. All its systems are developed and hosted exclusively in Switzerland. Supertext is supporting the Swiss {ai} Weeks with free API access for all hackathons.\r\n\r\n> The Supertext API, launched in July 2025, allows users to automatically translate text and files in 28 languages - fast, reliable and secure. And it can do even more in its paid version. With a Supertext API subscription you can tran...","hashtag":"","id":62,"ident":"","image_url":"https://avatars.githubusercontent.com/u/6619509?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"Supertext is a Swiss language AI provider offering secure and customisable AI translation in 28 languages. All its systems are developed and hosted exclusively in Switzerland. Supertext is supporting the Swiss {ai} Weeks with free API access for all hackathons.\r\n\r\n> The Supertext API, launched in July 2025, allows users to automatically translate text and files in 28 languages - fast, reliable and secure. And it can do even more in its paid version. With a Supertext API subscription you can translate content from any third-party system automatically - and bring in experienced linguists to verify the AI output in minutes. Our goal is to create an all-in-one language workspace, where each intervention by professional linguists further improves and customises any user\u2019s personal AI translation system.\r\n\r\n[Full documentation ...](https://www.supertext.com/en/documentation/swiss-ai-weeks)\r\n\r\nSpecial offer for participants of the {ai} Hackathon:\r\n\r\n\ud83d\udc49 https://supertext.ubpages.com/api-swiss-ai-weeks/\r\n\r\n---\r\n\r\n#### Evaluating Supertext\r\n\r\nThe code below is from a 2025 study that compares DeepL and Supertext by assessing their performance on unsegmented texts. The authors include Alex Fl\u00fcckiger, Chantal Amrhein, Tim Graf, Fr\u00e9d\u00e9ric Odermatt, Martin P\u00f6msl, Philippe Schl\u00e4pfer, Florian Schottmann, Samuel L\u00e4ubli - [open access](https://arxiv.org/abs/2502.02577)","maintainer":"loleg","name":"Supertext","phase":"Project","progress":5,"score":29,"source_url":"https://github.com/Supertext/evaluation_deepl_supertext","stats":{"commits":2,"during":4,"people":0,"sizepitch":1370,"sizetotal":2875,"total":4,"updates":3},"summary":"Supertext is a Swiss language AI provider offering secure and customisable AI translation in 28 languages.","team":"loleg","team_count":0,"updated_at":"2025-09-19T07:38","url":"https://swissai.dribdat.cc/project/62","webpage_url":"https://www.supertext.com"},{"autotext":"# \u26d3\ufe0f\ud83d\udee0\ufe0f ChainForge \r\n\r\n**An open-source visual environment for battle-testing prompts to LLMs.** [![Mentioned in Awesome Chainforge](https://awesome.re/mentioned-badge.svg)](https://github.com/loloMD/awesome_chainforge)\r\n\r\n<img width=\"1517\" alt=\"banner\" src=\"https://github.com/ianarawjo/ChainForge/assets/5251713/570879ef-ef8a-4e00-b37c-b49bc3c1a370\">\r\n\r\nChainForge is a data flow prompt engineering environment for analyzing and evaluating LLM responses. It enables rapid-fire, quick-and-dirty comparison of prompts, models, and response quality that goes beyond ad-hoc chatting with individual LLMs. With ChainForge, you can:\r\n\r\n- **Query multiple LLMs at once** to test prompt ideas and variations quickly and effectively.\r\n- **Compare response quality across prompt permutations, across models, and across model settings** to choose the best prompt and model for your use case.\r\n- **Setup evaluation metrics** (scoring function) and immediately visualize results across prompts, prompt parameters, models, and model settings.\r\n- **Use AI to streamline this entire process**: Create synthetic tables and input examples with built-in genAI features, or supercharge writing evals by prompting a model to give you starter code.  \r\n\r\n[Read the docs to learn more.](https://chainforge.ai/docs/) ChainForge comes with a number of example evaluation flows to give you a sense of what's possible, including 188 example flows generated from benchmarks in OpenAI evals.\r\n\r\nChainForge is built on [ReactFlow](https://reactflow.dev) and [Flask](https://flask.palletsprojects.com/en/2.3.x/).\r\n\r\n**_For user-curated resources and learning materials, check out the [\ud83c\udf1fAwesome ChainForge](https://github.com/loloMD/awesome_chainforge) repo!_** \r\n\r\n\r\n# Table of Contents\r\n\r\n- \ud83d\udc49 [Documentation](https://chainforge.ai/docs/) \ud83d\udcd6\r\n- [Installation](#installation)\r\n- [Example Experiments](#example-experiments)\r\n- [Share with Others](#share-with-others)\r\n- [Features](#features) (see the [docs](https://chainforge.ai/docs/nodes/) for more comprehensive info)\r\n- [Development and How to Cite](#development)\r\n\r\n# Installation\r\n\r\nYou can install ChainForge locally, or try it out on the web at **https://chainforge.ai/play/**. The web version of ChainForge has a limited feature set. In a locally installed version you can load API keys automatically from environment variables, write Python code to evaluate LLM responses, or query locally-run models hosted via Ollama.\r\n\r\nTo install Chainforge on your machine, make sure you have Python 3.8 or higher, then run\r\n\r\n```bash\r\npip install chainforge\r\n```\r\n\r\nOnce installed, do\r\n\r\n```bash\r\nchainforge serve\r\n```\r\n\r\nOpen [localhost:8000](http://localhost:8000/) in a Google Chrome, Firefox, Microsoft Edge, or Brave browser.\r\n\r\nYou can set your API keys by clicking the Settings icon in the top-right corner. If you prefer to not worry about this everytime you open ChainForge, we **highly recommend** that save your OpenAI, Anthropic, Google, etc API keys and/or Amazon AWS credentials to your local environment. For more details, see the [How to Install](https://chainforge.ai/docs/getting_started/).\r\n\r\n## Run using Docker\r\n\r\nYou can use our [Dockerfile](/Dockerfile) to run `ChainForge` locally using `Docker Desktop`:\r\n\r\n- Build the `Dockerfile`:\r\n  ```shell\r\n  docker build -t chainforge .\r\n  ```\r\n\r\n- Run the image:\r\n  ```shell\r\n  docker run -p 8000:8000 chainforge\r\n  ```\r\n\r\nNow you can open the browser of your choice and open `http://127.0.0.1:8000`.\r\n\r\n# Supported providers\r\n\r\n- OpenAI\r\n- Anthropic\r\n- Google (Gemini, PaLM2)\r\n- DeepSeek\r\n- HuggingFace (Inference and Endpoints)\r\n- Together.ai\r\n- [Ollama API](https://github.com/jmorganca/ollama) (locally-hosted models)\r\n- Microsoft Azure OpenAI Endpoints\r\n- [Aleph Alpha](https://docs.aleph-alpha.com/docs/introduction)\r\n- Amazon Bedrock-hosted on-demand inference, including Anthropic Claude 3\r\n- ...and any other provider through [custom provider scripts](https://chainforge.ai/docs/custom_providers/)!\r\n\r\n# Example experiments\r\n\r\nWe've prepared many example flows to give you a sense of what's possible with Chainforge.\r\nClick the \"Example Flows\" button on the top-right corner and select one. Here is a basic comparison example, plotting the length of responses across different models and arguments for the prompt parameter `{game}`:\r\n\r\n<img width=\"1593\" alt=\"basic-compare\" src=\"https://github.com/ianarawjo/ChainForge/assets/5251713/43c87ab7-aabd-41ba-8d9b-e7e9ebe25c75\">\r\n\r\nYou can also conduct **ground truth evaluations** using Tabular Data nodes. For instance, we can compare each LLM's ability to answer math problems by comparing each response to the expected answer:\r\n\r\n<img width=\"1775\" alt=\"Screen Shot 2023-07-04 at 9 21 50 AM\" src=\"https://github.com/ianarawjo/ChainForge/assets/5251713/6d842f7a-f747-44f9-b317-95bec73653c5\">\r\n\r\nJust import a dataset, hook it up to a template variable in a Prompt Node, and press run. \r\n\r\n# Compare responses across models and prompts\r\n\r\nCompare across models and prompt variables with an interactive response inspector, including a formatted table and exportable data:\r\n\r\n<img width=\"1460\" alt=\"Screen Shot 2023-07-19 at 5 03 55 PM\" src=\"https://github.com/ianarawjo/ChainForge/assets/5251713/6aca2bd7-7820-4256-9e8b-3a87795f3e50\">\r\n\r\nThe key power of ChainForge lies in **combinatorial power**: ChainForge takes the _cross product_ of inputs to prompt templates, meaning you can produce every combination of input values.\r\nThis is incredibly effective at sending off hundreds of queries at once to verify model behavior more robustly than one-off prompting. \r\n\r\nHere's [a tutorial to get started comparing across prompt templates](https://chainforge.ai/docs/compare_prompts/).\r\n\r\n# Share with others\r\n\r\nThe web version of ChainForge (https://chainforge.ai/play/) includes a Share button.\r\n\r\nSimply click Share to generate a unique link for your flow and copy it to your clipboard:\r\n\r\n![ezgif-2-a4d8048bba](https://github.com/ianarawjo/ChainForge/assets/5251713/1c69900b-5a0f-4055-bbd3-ea191e93ecde)\r\n\r\nFor instance, here's a experiment I made that tries to get an LLM to reveal a secret key: https://chainforge.ai/play/?f=28puvwc788bog\r\n\r\n> **Note**\r\n> To prevent abuse, you can only share up to 10 flows at a time, and each flow must be <5MB after compression.\r\n> If you share more than 10 flows, the oldest link will break, so make sure to always Export important flows to `cforge` files,\r\n> and use Share to only pass data ephemerally.\r\n\r\nFor finer details about the features of specific nodes, check out the [List of Nodes](https://chainforge.ai/docs/nodes/).\r\n\r\n# Features\r\n\r\nA key goal of ChainForge is facilitating **comparison** and **evaluation** of prompts and models. Overall, you can:\r\n\r\n- **Compare across prompts and prompt parameters**: Find the best set of prompts that maximizes your eval target metrics (e.g., lowest code error rate). Or, see how changing parameters in a prompt template affects the quality of responses.\r\n- **Compare across models**: Compare responses for every prompt across models and different model settings, to find the best model for your use case. \r\n\r\nThe features that enable this area:\r\n\r\n- **Prompt permutations**: Setup a prompt template and feed it variations of input variables. ChainForge will prompt all selected LLMs with all possible permutations of the input prompt, so that you can get a better sense of prompt quality. You can also chain prompt templates at arbitrary depth (e.g., to compare templates).\r\n- **Model settings**: Change the settings of supported models, and compare across settings. For instance, you can measure the impact of a system message on ChatGPT by adding several ChatGPT models, changing individual settings, and nicknaming each one. ChainForge will send out queries to each version of the model.\r\n- **Evaluation nodes**: Probe LLM responses in a chain and test them (classically) for some desired behavior. At a basic level, this is Python script based. We plan to add preset evaluator nodes for common use cases in the near future (e.g., name-entity recognition). Note that you can also chain LLM responses into prompt templates to help evaluate outputs cheaply before more extensive evaluation methods.\r\n- **Visualization nodes**: Visualize evaluation results on plots like grouped box-and-whisker (for numeric metrics) and histograms (for boolean metrics). Currently we only support numeric and boolean metrics. We aim to provide users more control and options for plotting in the future.\r\n- **Chat turns**: Go beyond prompts and template follow-up chat messages, just like prompts. You can test how the wording of the user's query might change an LLM's output, or compare quality of later responses across multiple chat models (or the same chat model with different settings!).\r\n\r\nAlongside built-in [gen AI features \ud83e\ude84\ud83d\udcab](https://chainforge.ai/docs/gen_ai/) like synthetic data generation, prompt engineering is accelerated: you can compare prompts and model performance sometimes **_without needing to write a single line of code_**, speeding up the process of iteration and discovery tenfold. \r\n\r\nWe've also found that some users simply want to use ChainForge to make tons of parametrized queries to LLMs (e.g., chaining prompt templates into prompt templates), possibly score them, and then output the results to a spreadsheet (Excel `xlsx`). To do this, attach an Inspect node to the output of a Prompt node and click `Export Data`.\r\n\r\nFor more specific details, see our [documentation](https://chainforge.ai/docs/nodes/).\r\n\r\n---\r\n\r\n# Development\r\n\r\nChainForge was created by [Ian Arawjo](http://ianarawjo.com/index.html), a postdoctoral scholar in Harvard HCI's [Glassman Lab](http://glassmanlab.seas.harvard.edu/) with support from the Harvard HCI community. Collaborators include PhD students [Priyan Vaithilingam](https://priyan.info) and [Chelse Swoopes](https://seas.harvard.edu/person/chelse-swoopes), Harvard undergraduate [Sean Yang](https://shawsean.com), and faculty members [Elena Glassman](http://glassmanlab.seas.harvard.edu/glassman.html) and [Martin Wattenberg](https://www.bewitched.com/about.html). Additional collaborators include UC Berkeley PhD student Shreya Shankar and Universit\u00e9 de Montr\u00e9al undergraduate Cassandre Hamel.\r\n\r\nThis work was partially funded by the NSF grants IIS-2107391, IIS-2040880, and IIS-1955699. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.\r\n\r\nWe provide ongoing releases of this tool in the hopes that others find it useful for their projects.\r\n\r\n## Inspiration and Links\r\n\r\nChainForge is meant to be general-purpose, and is not developed for a specific API or LLM back-end. Our ultimate goal is integration into other tools for the systematic evaluation and auditing of LLMs. We hope to help others who are developing prompt-analysis flows in LLMs, or otherwise auditing LLM outputs. This project was inspired by own our use case, but also shares some comraderie with two related (closed-source) research projects, both led by [Sherry Wu](https://www.cs.cmu.edu/~sherryw/):\r\n\r\n- \"PromptChainer: Chaining Large Language Model Prompts through Visual Programming\" (Wu et al., CHI \u201922 LBW) [Video](https://www.youtube.com/watch?v=p6MA8q19uo0)\r\n- \"AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts\" (Wu et al., CHI \u201922)\r\n\r\nUnlike these projects, we are focusing on supporting evaluation across prompts, prompt parameters, and models.\r\n\r\n## How to collaborate?\r\n\r\nWe welcome open-source collaborators. If you want to report a bug or request a feature, open an [Issue](https://github.com/ianarawjo/ChainForge/issues). We also encourage users to implement the requested feature / bug fix and submit a Pull Request.\r\n\r\n---\r\n\r\n# Cite Us\r\n\r\nIf you use ChainForge for research purposes, whether by building upon the source code or investigating LLM behavior using the tool, we ask that you cite our [CHI research paper](https://dl.acm.org/doi/full/10.1145/3613904.3642016) in any related publications. The BibTeX you can use is:\r\n\r\n```bibtex\r\n@inproceedings{arawjo2024chainforge,\r\n  title={ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing},\r\n  author={Arawjo, Ian and Swoopes, Chelse and Vaithilingam, Priyan and Wattenberg, Martin and Glassman, Elena L},\r\n  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},\r\n  pages={1--18},\r\n  year={2024}\r\n}\r\n```\r\n\r\n# License\r\n\r\nChainForge is released under the MIT License.\r\n","autotext_url":"https://github.com/ianarawjo/ChainForge","category_id":"","category_name":"","contact_url":"https://github.com/ianarawjo/ChainForge/issues","created_at":"2025-05-27T09:34","download_url":"https://chainforge.ai/play","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"Further resources on prompt engineering, from a [workshop at BFH](https://www.bfh.ch/en/news/events-for-specialists/swiss-ai-weeks-ai-for-smes/):\r\n\r\n- https://romanrietsche.github.io/talk/bfh_research/\r\n- https://www.deeplearning.ai/courses/\r\n- https://www.datacamp.com/tutorial/few-shot-prompting\r\n- https://www.promptingguide.ai/techniques/cot","hashtag":"","id":9,"ident":"","image_url":"https://avatars.githubusercontent.com/u/5251713?v=4","is_challenge":false,"is_webembed":true,"logo_color":"","logo_icon":"","longtext":"Further resources on prompt engineering, from a [workshop at BFH](https://www.bfh.ch/en/news/events-for-specialists/swiss-ai-weeks-ai-for-smes/):\r\n\r\n- https://romanrietsche.github.io/talk/bfh_research/\r\n- https://www.deeplearning.ai/courses/\r\n- https://www.datacamp.com/tutorial/few-shot-prompting\r\n- https://www.promptingguide.ai/techniques/cot","maintainer":"loleg","name":"ChainForge","phase":"Research","progress":10,"score":27,"source_url":"https://github.com/ianarawjo/ChainForge","stats":{"commits":0,"during":1,"people":0,"sizepitch":345,"sizetotal":13048,"total":3,"updates":2},"summary":"Visual programming environment for battle-testing prompts to LLMs","team":"loleg","team_count":0,"updated_at":"2025-09-19T07:14","url":"https://swissai.dribdat.cc/project/9","webpage_url":""},{"autotext":"# llm-benchmark (ollama-benchmark)\r\n\r\nLLM Benchmark for Throughput via Ollama (Local LLMs)\r\n\r\nMeasure how fast your local LLMs *really* are\u2014with a simple, cross-platform CLI tool that tells you the tokens-per-second truth.\r\n\r\n## Installation prerequisites\r\n\r\nWorking [Ollama](https://ollama.com) installation.\r\n\r\n## Installation Steps\r\n\r\nDepending on your python setup either\r\n\r\n```bash\r\npip install llm-benchmark\r\n```\r\n\r\nor\r\n\r\n```bash\r\npipx install llm-benchmark\r\n```\r\n\r\n## Usage for general users directly\r\n\r\n```bash\r\nllm_benchmark run\r\n```\r\n\r\n## Installation and Usage in Video format\r\n\r\n![llm-benchmark](https://github.com/aidatatools/ollama-benchmark/blob/main/llm-benchmark.gif)\r\n\r\nIt's tested on Python 3.9 and above.\r\n\r\n## ollama installation with the following models installed\r\n\r\n7B model can be run on machines with 8GB of RAM\r\n\r\n13B model can be run on machines with 16GB of RAM\r\n\r\n## Usage explaination\r\n\r\nOn Windows, Linux, and macOS, it will detect memory RAM size to first download required LLM models.\r\n\r\nWhen memory RAM size is greater than or equal to 4GB, but less than 7GB, it will check if gemma:2b exist. The program implicitly pull the model.\r\n\r\n```bash\r\nollama pull deepseek-r1:1.5b\r\nollama pull gemma:2b\r\nollama pull phi:2.7b\r\nollama pull phi3:3.8b\r\n```\r\n\r\nWhen memory RAM size is greater than 7GB, but less than 15GB, it will check if these models exist. The program implicitly pull these models\r\n\r\n```bash\r\nollama pull phi3:3.8b\r\nollama pull gemma2:9b\r\nollama pull mistral:7b\r\nollama pull llama3.1:8b\r\nollama pull deepseek-r1:8b\r\nollama pull llava:7b\r\n```\r\n\r\nWhen memory RAM size is greater than 15GB, but less than 31GB, it will check if these models exist. The program implicitly pull these models\r\n\r\n```bash\r\nollama pull gemma2:9b\r\nollama pull mistral:7b\r\nollama pull phi4:14b\r\nollama pull deepseek-r1:8b\r\nollama pull deepseek-r1:14b\r\nollama pull llava:7b\r\nollama pull llava:13b\r\n```\r\n\r\nWhen memory RAM size is greater than 31GB, it will check if these models exist. The program implicitly pull these models\r\n\r\n```bash\r\nollama pull phi4:14b\r\nollama pull deepseek-r1:14b\r\nollama pull gpt-oss:20b\r\n```\r\n\r\n## Python Poetry manually(advanced) installation\r\n\r\n<https://python-poetry.org/docs/#installing-manually>\r\n\r\n## For developers to develop new features on Windows Powershell or on Ubuntu Linux or macOS\r\n\r\n```bash\r\npython3 -m venv .venv\r\n. ./.venv/bin/activate\r\npip install -U pip setuptools\r\npip install poetry\r\n```\r\n\r\n## Usage in Python virtual environment\r\n\r\n```bash\r\npoetry shell\r\npoetry install\r\nllm_benchmark hello jason\r\n```\r\n\r\n### Example #1 send systeminfo and benchmark results to a remote server\r\n\r\n```bash\r\nllm_benchmark run\r\n```\r\n\r\n### Example #2 Do not send systeminfo and benchmark results to a remote server\r\n\r\n```bash\r\nllm_benchmark run --no-sendinfo\r\n```\r\n\r\n### Example #3 Benchmark run on explicitly given the path to the ollama executable (When you built your own developer version of ollama)\r\n\r\n```bash\r\nllm_benchmark run --ollamabin=~/code/ollama/ollama\r\n```\r\n\r\n### Example #4 run custom benchmark models\r\n\r\n1. Create a custom benchmark file like following yaml format, replace with your own benchmark models, remember to use double quote for your model name\r\n\r\n```yaml\r\nfile_name: \"custombenchmarkmodels.yml\"\r\nversion: 2.0.custom\r\nmodels:\r\n  - model: \"deepseek-r1:1.5b\"\r\n  - model: \"qwen:0.5b\"\r\n```\r\n\r\n2. run with the flag and point to the path of custombenchmarkmodels.yml\r\n\r\n```bash\r\nllm_benchmark run --custombenchmark=path/to/custombenchmarkmodels.yml\r\n```\r\n\r\n## Reference\r\n\r\n[Ollama](https://ollama.com)\r\n","autotext_url":"https://github.com/aidatatools/ollama-benchmark","category_id":"","category_name":"","contact_url":"https://github.com/aidatatools/ollama-benchmark/issues","created_at":"2025-09-05T09:41","download_url":"https://llm.aidatatools.com/","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"# llm-benchmark (ollama-benchmark)\r\n\r\nLLM Benchmark for Throughput via Ollama (Local LLMs)\r\n\r\nMeasure how fast your local LLMs *really* are\u2014with a simple, cross-platform CLI tool that tells you the tokens-per-second truth.\r\n\r\n## Installation prerequisites\r\n\r\nWorking [Ollama](https://ollama.com) installation.\r\n\r\n## Installation Steps\r\n\r\nDepending on your python setup either\r\n\r\n```bash\r\npip install llm-benchmark\r\n```\r\n\r\nor\r\n\r\n```bash\r\npipx install llm-benchmark\r\n```\r\n\r\n## Usage for general users d...","hashtag":"","id":57,"ident":"","image_url":"https://avatars.githubusercontent.com/u/114840075?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"","maintainer":"loleg","name":"Ollama benchmark","phase":"Research","progress":10,"score":26,"source_url":"https://github.com/aidatatools/ollama-benchmark","stats":{"commits":7,"during":9,"people":0,"sizepitch":0,"sizetotal":3617,"total":9,"updates":8},"summary":"LLM Benchmark for Throughput via Ollama (Local LLMs)","team":"loleg","team_count":0,"updated_at":"2025-09-09T15:00","url":"https://swissai.dribdat.cc/project/57","webpage_url":""},{"autotext":"<div align=\"center\">\r\n    <h1><img height=\"150px\" src=\"https://raw.githubusercontent.com/logic-star-ai/baxbench/main/./static/baxbench_icon.png\" alt=\"BaxBench\"><br>BaxBench</h1>\r\n\r\n  <a href=\"https://www.python.org/\">\r\n<img alt=\"Build\" src=\"https://img.shields.io/badge/Python-3.12-1f425f.svg?color=blue\">\r\n  </a>\r\n  <a href=\"https://opensource.org/licenses/MIT\">\r\n<img alt=\"License: MIT\" src=\"https://img.shields.io/badge/License-MIT-yellow.svg\">\r\n  </a>\r\n\r\n</div>\r\n\r\n## \ud83d\udc4b Overview\r\n\r\nBaxBench is a coding benchmark for evaluating the ability of LLMs on generating correct and secure code in realistic, security-critical settings.\r\nEach coding task in BaxBench consists of a *scenario*, describing the API the backend application should implement, and a *framework*, fixing the implementation language and backend framework to use.\r\nThe scenarios can be found [here](src/scenarios/), while all supported frameworks are included [here](src/env/).\r\n\r\n> For more details and model evaluations, read our paper [BaxBench: Can LLMs Generate Secure and Correct Backends?](https://arxiv.org/abs/2502.11844) or visit our [website](https://baxbench.com).\r\n\r\n### Assets\r\n\r\n- \ud83d\udcdc Paper: [BaxBench: Can LLMs Generate Secure and Correct Backends?](https://arxiv.org/abs/2502.11844)\r\n- \ud83c\udfc6 Website & Leaderboard: [baxbench.com](https://baxbench.com)\r\n- \ud83e\udd17 Dataset: [datasets/LogicStar/BaxBench](https://huggingface.co/datasets/LogicStar/BaxBench)\r\n\r\n## \ud83d\ude80 Installation\r\n\r\n**Prerequisites:**\r\n\r\n> `python 3.12`: Install it from [here](https://www.python.org/downloads/).<br>\r\n> `docker`: Follow the instructions for installing docker desktop [here](https://docs.docker.com/desktop/) (Windows, MacOS, Linux) or for the docker engine [here](https://docs.docker.com/engine/install/) (Linux). Make sure that docker has root privileges on your machine.<br>\r\n> `pipenv`: The project uses pipenv for package management. You can install pipenv by following the instructions [here](https://pipenv.pypa.io/en/latest/).\r\n\r\n**Setting up the environment and running scripts**\r\n\r\nAfter ensuring that all prerequisites are installed, you can install the environment by running `pipenv install` from the root of the repository. Please ensure that this action does not change `Pipfile.lock`. To run any python script in the project environment, run always from the project root using the command:\r\n```bash\r\npipenv run python <path_to_python_script> <args>\r\n```\r\n\r\n**Setting API keys**\r\n\r\nTo generate BaxBench task solutions, the current repository requires the user to set the following environment variables to API keys stored in environment variables in your `.bashrc` or the equivalent configuration file of your system:\r\n\r\n```bash\r\nexport OPENAI_API_KEY=\"<your_API_key>\"\r\nexport TOGETHER_API_KEY=\"<your_API_key>\"\r\nexport ANTHROPIC_API_KEY=\"<your_API_key>\"\r\nexport OPENROUTER_API_KEY=\"<your_API_key>\"\r\n```\r\n\r\n> **Note:** You may set any API key you do not intend to use simply to an empty or invalid string.\r\n\r\n## \ud83d\udcab Contributing\r\n\r\nWe welcome contributions from the community. You may contribute by:\r\n- Adding a scenario:\r\n    > Create a new scenario in the `scenarios` directory. Look at other scenarios as an example for what has to be there for completeness.<br>\r\n    > Add the scenario to the `scenarios` list in `src/scenarios/__init__.py`.<br>\r\n    > Open a pull request to integrate your scenario into the main branch. <br>\r\n- Adding a new framework:\r\n    > Create a new scenario in the `env` directory. Look at other environments as an example for what has to be there for completeness.<br>\r\n    > Add the scenario to the `envs` list in `src/env/__init__.py`.<br>\r\n    > Open a pull request to integrate your scenario into the main branch. <br>\r\n- Adding tests to a scenario:\r\n    > Open a pull request modifying the given scenario file to add further functionality tests or security exploits.\r\n- Raising issues or giving feedback:\r\n    > If you identify any issues or want to share feedback with us, you may either contact us directly or raise an issue on GitHub.\r\nWe are looking forward to working with the community and are extremely thankful for any contributions!\r\n\r\n> **Note:** Before contributing code, please run `pipenv run pre-commit install` in the root once to set up the pre-commit hooks.\r\n\r\n## \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbb Usage\r\n\r\n#### Generating programs\r\n\r\nTo generate solutions to _all_ scenarios in the `scenarios` list, run the following command:\r\n\r\n`pipenv run python src/main.py --models gpt-4o --mode generate --n_samples 10 --temperature 0.4`\r\n\r\nTo restrict the generation to a subset of scenarios or environments, see the [\"Advanced\" section](#advanced) below.\r\n\r\nThe programs and the generation logs will be saved in the directory `results`.\r\n\r\n#### Testing generated programs\r\n\r\nRun: `pipenv run python src/main.py --models gpt-4o --mode test --n_samples 10 --temperature 0.4` to test your generated solutions.\r\n\r\nIf you have generated solutions externally, e.g., using our [Hugging Face dataset](https://huggingface.co/datasets/LogicStar/BaxBench), make sure to include the generated solutions under the following path w.r.t. the root of this repository:\r\n\r\n`results/<model_name>/<scenario_id>/<env_id>/temp<t>-<spec_type>-<prompt_type>/sample<s>/code`\r\n\r\nThen set the corresponding parameters in the testing command accordingly. See [\"Advanced\"](#advanced) below or the argument list in [main.py](src/main.py).\r\n\r\n#### Evaluating and printing\r\n\r\nRun: `pipenv run python src/main.py --models gpt-4o --mode evaluate --n_samples 10 --temperature 0.4` to print your results to a table in your console.\r\n\r\n#### Advanced\r\n\r\nSpecific models/scenarios/frameworks/samples can be generated, tested, or evaluated by specifying the following arguments in the CLI:\r\n\r\n```\r\n--models\r\n--scenarios\r\n--envs\r\n--only_samples\r\n--safety_prompt\r\n--spec_type\r\n```\r\n\r\nEach of these arguments takes values separated by spaces.\r\n\r\n## \u270d\ufe0f Citation\r\nIf you find our work helpful, please use the following citations.\r\n```bib\r\n@article{vero2025baxbenchllmsgeneratecorrect,\r\n        title={BaxBench: Can LLMs Generate Correct and Secure Backends?}, \r\n        author={Mark Vero and Niels M\u00fcndler and Victor Chibotaru and Veselin Raychev and Maximilian Baader and Nikola Jovanovi\u0107 and Jingxuan He and Martin Vechev},\r\n        year={2025},\r\n        eprint={2502.11844},\r\n        archivePrefix={arXiv},\r\n}\r\n```\r\n\r\n## \ud83d\udcdd License\r\nMIT. Check `LICENSE`.\r\n","autotext_url":"https://github.com/logic-star-ai/baxbench","category_id":"","category_name":"","contact_url":"https://github.com/logic-star-ai/baxbench/issues","created_at":"2025-09-12T19:57","download_url":"https://github.com/logic-star-ai/baxbench/releases","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"BaxBench is a coding benchmark for evaluating the ability of LLMs on generating correct and secure code in realistic, security-critical settings. Each coding task in BaxBench consists of a scenario, describing the API the backend application should implement, and a framework, fixing the implementation language and backend framework to use.","hashtag":"","id":64,"ident":"","image_url":"https://avatars.githubusercontent.com/u/171349138?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"BaxBench is a coding benchmark for evaluating the ability of LLMs on generating correct and secure code in realistic, security-critical settings. Each coding task in BaxBench consists of a scenario, describing the API the backend application should implement, and a framework, fixing the implementation language and backend framework to use.","maintainer":"loleg","name":"baxbench","phase":"Research","progress":10,"score":26,"source_url":"https://github.com/logic-star-ai/baxbench","stats":{"commits":0,"during":2,"people":0,"sizepitch":341,"sizetotal":6734,"total":2,"updates":1},"summary":"","team":"loleg","team_count":0,"updated_at":"2025-09-19T07:15","url":"https://swissai.dribdat.cc/project/64","webpage_url":""},{"autotext":"# Open Language Model Evaluation System (OLMES)\r\n\r\n## Introduction\r\n\r\nThe OLMES (Open Language Model Evaluation System) repository is used within [Ai2](https://allenai.org)'s Open \r\nLanguage Model efforts to evaluate base and\r\ninstruction-tuned LLMs on a range of tasks. The repository includes code to faithfully reproduce the \r\nevaluation results in research papers such as\r\n   * **OLMo:** Accelerating the Science of Language Models ([Groeneveld et al, 2024](https://www.semanticscholar.org/paper/ac45bbf9940512d9d686cf8cd3a95969bc313570))\r\n   * **OLMES:** A Standard for Language Model Evaluations ([Gu et al, 2024](https://www.semanticscholar.org/paper/c689c37c5367abe4790bff402c1d54944ae73b2a))\r\n   * **T\u00dcLU 3:** Pushing Frontiers in Open Language Model Post-Training ([Lambert et al, 2024](https://www.semanticscholar.org/paper/T/%22ULU-3%3A-Pushing-Frontiers-in-Open-Language-Model-Lambert-Morrison/5ca8f14a7e47e887a60e7473f9666e1f7fc52de7))\r\n   * **OLMo 2:** 2 OLMo 2 Furious ([Team OLMo et al, 2024](https://arxiv.org/abs/2501.00656))\r\n\r\nThe code base uses helpful features from the [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness) \r\nby Eleuther AI, with a number of modifications and enhancements, including:\r\n\r\n  * Support deep configurations for variants of tasks\r\n  * Record more detailed data about instance-level predictions (logprobs, etc)\r\n  * Custom metrics and metric aggregations\r\n  * Integration with external storage options for results\r\n\r\n\r\n## Setup\r\n\r\nStart by cloning the repository and install dependencies (optionally creating a virtual environment,\r\nPython 3.10 or higher is recommended):\r\n```\r\ngit clone https://github.com/allenai/olmes.git\r\ncd olmes\r\n\r\nconda create -n olmes python=3.10\r\nconda activate olmes\r\npip install -e .\r\n```\r\n\r\nFor running on GPUs (with vLLM), use instead `pip install -e .[gpu]`. If you get complaints regarding the \r\n`torch` version, downgrade to `torch>=2.2` in [pyproject.toml](pyproject.toml).\r\n\r\n## Running evaluations\r\n\r\nTo run an evaluation with a specific model and task (or task suite):\r\n\r\n```commandline\r\nolmes --model olmo-1b --task arc_challenge::olmes --output-dir my-eval-dir1\r\n```\r\n\r\nThis will launch the standard [OLMES](https://www.semanticscholar.org/paper/c689c37c5367abe4790bff402c1d54944ae73b2a) \r\nversion of [ARC Challenge](https://www.semanticscholar.org/paper/88bb0a28bb58d847183ec505dda89b63771bb495) \r\n(which uses a curated 5-shot example, trying both multiple-choice and cloze formulations, and reporting\r\nthe max) with the [pythia-1b model](https://huggingface.co/EleutherAI/pythia-1b), storing the output in `my-eval-dir1`\r\n\r\nMultiple tasks can be specified after the `--task` argument, e.g.,\r\n```commandline\r\nolmes --model olmo-1b --task arc_challenge::olmes hellaswag::olmes --output-dir my-eval-dir1\r\n```\r\n\r\nBefore starting an evaluation, you can sanity check using `--inspect`, which shows a sample prompt\r\n(and does a tiny 5-instance eval with a small model)\r\n```commandline\r\nolmes --task arc_challenge:mc::olmes --inspect\r\n```\r\nYou can also look at the fully expanded command of the job you are about launch using the `--dry-run` flag:\r\n```commandline\r\nolmes --model pythia-1b --task mmlu::olmes --output-dir my-eval-dir1 --dry-run\r\n```\r\n\r\nFor a full list of arguments run `olmes --help`.\r\n\r\n\r\n## Running specific evaluation suites\r\n\r\n### OLMES standard - Original 10 multiple-choice tasks\r\n\r\nTo run all 10 multiple-choice tasks from the [OLMES paper](https://www.semanticscholar.org/paper/c689c37c5367abe4790bff402c1d54944ae73b2a):\r\n```\r\nolmes --model olmo-7b --task core_9mcqa::olmes --output-dir <dir>\r\nolmes --model olmo-7b --task mmlu::olmes --output-dir <dir>\r\n```\r\n\r\n### OLMo evaluations\r\n\r\nTo reproduce numbers in the [OLMo paper](https://www.semanticscholar.org/paper/ac45bbf9940512d9d686cf8cd3a95969bc313570):\r\n```\r\nolmes --model olmo-7b --task main_suite::olmo1 --output-dir <dir>\r\nolmes --model olmo-7b --task mmlu::olmo1 --output-dir <dir>\r\n```\r\n\r\n### T\u00dcLU 3 evaluations\r\n\r\nThe list of exact tasks and associated formulations used in the [T\u00dcLU 3 \r\nwork](https://www.semanticscholar.org/paper/T/%22ULU-3%3A-Pushing-Frontiers-in-Open-Language-Model-Lambert-Morrison/5ca8f14a7e47e887a60e7473f9666e1f7fc52de7) \r\ncan be found in these  suites in the [task suite library](oe_eval/configs/task_suites.py):\r\n   *  `\"tulu_3_dev\"`: Tasks evaluated during development\r\n   * `\"tulu_3_unseen\"`: Held-out task used during final evaluation\r\n\r\n### OLMo 2 evaluations\r\n\r\nThe list of exact tasks and associated formulations used in the base model evaluations of the \r\n[OLMo 2 technical report]()\r\ncan be found in these suites in the [task suite library](oe_eval/configs/task_suites.py):\r\n   * `\"core_9mcqa::olmes\"`: The core 9 multiple-choice tasks from original OLMES standard\r\n   * `\"mmlu:mc::olmes\"`: The MMLU tasks in multiple-choice format\r\n   * `\"olmo_2_generative::olmes\"`: The 5 generative tasks used in OLMo 2 development\r\n   * `\"olmo_2_heldout::olmes\"`: The 5 held-out tasks used in OLMo 2 final evaluation\r\n\r\n\r\n\r\n## Model configuration\r\n\r\nModels can be directly referenced by their Huggingface model path, e.g., `--model allenai/OLMoE-1B-7B-0924`,\r\nor by their key in the [model library](oe_eval/configs/models.py), e.g., `--model olmoe-1b-7b-0924` which\r\ncan include additional configuration options (such as `max_length` for max context size and `model_path` for\r\nlocal path to model).\r\n\r\nThe default model type uses the Huggingface model implementations, but you can also use the `--model-type vllm` flag to use\r\nthe vLLM implementations for models that support it, as well as `--model-type litellm` to run API-based models.\r\n\r\nYou can specify arbitrary JSON-parse-able model arguments directly in the command line as well, e.g.\r\n```commandline\r\nolmes --model google/gemma-2b --model-args '{\"trust_remote_code\": true, \"add_bos_token\": true}' ...\r\n```\r\nTo see a list of available models, run `oe-eval --list-models`, for a list of models containing a certain phrase,\r\nyou can follow this with a substring (any regular expression), e.g., `oe-eval --list-models llama`.\r\n\r\n\r\n## Task configuration\r\n\r\nTo specify a task, use the [task library](oe_eval/configs/tasks.py) which have\r\nentries like\r\n```\r\n\"arc_challenge:rc::olmes\": {\r\n    \"task_name\": \"arc_challenge\",\r\n    \"split\": \"test\",\r\n    \"primary_metric\": \"acc_uncond\",\r\n    \"num_shots\": 5,\r\n    \"fewshot_source\": \"OLMES:ARC-Challenge\",\r\n    \"metadata\": {\r\n        \"regimes\": [\"OLMES-v0.1\"],\r\n    },\r\n},\r\n```\r\nEach task can also have custom entries for `context_kwargs` (controlling details of the prompt),\r\n`generation_kwargs` (controlling details of the generation), and `metric_kwargs` (controlling details of the metrics). The `primary_metric` indicates which metric field will be reported as the \"primary score\" for the task.\r\n\r\nThe task configuration parameters can be overridden on the command line, these will generally apply to all tasks, e.g.,\r\n```commandline\r\nolmes --task arc_challenge:rc::olmes hellaswag::rc::olmes --split dev ...\r\n```\r\nbut using a json format for each task, can be on per-task (but it's generally better to use the task \r\nlibrary for this), e.g.,\r\n```\r\nolmes --task '{\"task_name\": \"arc_challenge:rc::olmes\", \"num_shots\": 2}' '{\"task_name\": \"hellasag:rc::olmes\", \"num_shots\": 4}' ...\r\n```\r\nFor complicated commands like this, using `--dry-run` can be helpful to see the full command before running it.\r\n\r\nTo see a list of available tasks, run `oe-eval --list-tasks`, for a list of tasks containing a certain phrase,\r\nyou can follow this with a substring (any regular expression), e.g., `oe-eval --list-tasks arc`.\r\n\r\n### Task suite configurations\r\n\r\nTo define a suite of tasks to run together, use the [task suite library](oe_eval/configs/task_suites.py),\r\nwith entries like:\r\n```python\r\nTASK_SUITE_CONFIGS[\"mmlu:mc::olmes\"] = {\r\n    \"tasks\": [f\"mmlu_{sub}:mc::olmes\" for sub in MMLU_SUBJECTS],\r\n    \"primary_metric\": \"macro\",\r\n}\r\n```\r\nspecifying the list of tasks as well as how the metrics should be aggregated across the tasks.\r\n\r\n\r\n## Evaluation output\r\n\r\nThe evaluation output is stored in the specified output directory, in a set of files\r\nfor each task. See [output formats](OUTPUT_FORMATS.md) for more details.\r\n\r\nThe output can optionally be stored in a Google Sheet by specifying the `--gsheet` argument (with authentication\r\nstored in environment variable `GDRIVE_SERVICE_ACCOUNT_JSON`).\r\n\r\nThe output can also be stored in a Huggingface dataset directory by specifying the `--hf-save-dir` argument, \r\na remote directory (like `s3://...`) by specifying the `--remote-output-dir` argument,\r\nor in a W&B project by specifying the `--wandb-run-path` argument.\r\n","autotext_url":"https://github.com/allenai/olmes","category_id":"","category_name":"","contact_url":"https://github.com/allenai/olmes/issues","created_at":"2025-07-17T05:27","download_url":"https://github.com/allenai/olmes/releases","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"# Open Language Model Evaluation System (OLMES)\r\n\r\n## Introduction\r\n\r\nThe OLMES (Open Language Model Evaluation System) repository is used within [Ai2](https://allenai.org)'s Open \r\nLanguage Model efforts to evaluate base and\r\ninstruction-tuned LLMs on a range of tasks. The repository includes code to faithfully reproduce the \r\nevaluation results in research papers such as\r\n   * **OLMo:** Accelerating the Science of Language Models ([Groeneveld et al, 2024](https://www.semanticscholar.org/paper/...","hashtag":"","id":29,"ident":"","image_url":"https://avatars.githubusercontent.com/u/5667695?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"","maintainer":"loleg","name":"OLMES","phase":"Research","progress":10,"score":25,"source_url":"https://github.com/allenai/olmes","stats":{"commits":5,"during":7,"people":0,"sizepitch":0,"sizetotal":8715,"total":7,"updates":7},"summary":"Reproducible, flexible LLM evaluations","team":"loleg","team_count":0,"updated_at":"2025-07-17T05:28","url":"https://swissai.dribdat.cc/project/29","webpage_url":""},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2025-07-10T00:00","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"![](https://ai.epfl.ch/wp-content/uploads/Overview-of-Include-02.06.2025-2048x1168.jpg)\r\n\r\n> \"Teams from EPFL\u2019s Natural Language Processing Lab, Cohere Labs and collaborators across the globe have developed INCLUDE. This tool represents a significant step toward an AI more attuned to local contexts. The benchmark enables one to assess whether a LLM is not only accurate in a given language but also capable of integrating the culture and sociocultural realities associated with it. This approach al...","hashtag":"","id":23,"ident":"","image_url":"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Logo_EPFL.svg/330px-Logo_EPFL.svg.png","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"![](https://ai.epfl.ch/wp-content/uploads/Overview-of-Include-02.06.2025-2048x1168.jpg)\r\n\r\n> \"Teams from EPFL\u2019s Natural Language Processing Lab, Cohere Labs and collaborators across the globe have developed INCLUDE. This tool represents a significant step toward an AI more attuned to local contexts. The benchmark enables one to assess whether a LLM is not only accurate in a given language but also capable of integrating the culture and sociocultural realities associated with it. This approach aligns with the goals of the Swiss AI Initiative to create models that reflect Swiss languages and values.\"\r\nhttps://ai.epfl.ch/beyond-translation-making-ai-multicultural/\r\n\r\n**INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge** \\\r\nAngelika Romanou, Negar Foroutan, Anna Sotnikova, Zeming Chen, Sree \\\r\nHarsha Nelaturu, Shivalika Singh, Rishabh Maheshwary, Micol Altomare, \\\r\nMohamed A. Haggag, Imanol Schlag \\\r\nMarzieh Fadaee, Sara Hooker, Antoine Bosselut \\\r\nhttps://doi.org/10.48550/arXiv.2411.19799\r\n\r\n","maintainer":"loleg","name":"INCLUDE","phase":"Research","progress":10,"score":21,"source_url":"","stats":{"commits":0,"during":1,"people":0,"sizepitch":1030,"sizetotal":1105,"total":1,"updates":1},"summary":"A multilingual benchmark to determine LLM ability to grasp cultural context","team":"loleg","team_count":0,"updated_at":"2025-08-19T14:49","url":"https://swissai.dribdat.cc/project/23","webpage_url":""},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2025-07-14T17:37","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"> \"Hugging Face is organized around its Hugging Face Hub, where users can upload and discover models, datasets, and applications. Discussions happen through forums, GitHub repositories, and a lively Discord server. The culture is highly collaborative, open-minded, and supportive of both newcomers and experts. Community rituals like showcasing projects on \u201cSpaces\u201d and celebrating new model uploads have created a vibrant and inclusive atmosphere where inside jokes, model memes, and helpful tips ci...","hashtag":"","id":28,"ident":"","image_url":"https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.svg","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"> \"Hugging Face is organized around its Hugging Face Hub, where users can upload and discover models, datasets, and applications. Discussions happen through forums, GitHub repositories, and a lively Discord server. The culture is highly collaborative, open-minded, and supportive of both newcomers and experts. Community rituals like showcasing projects on \u201cSpaces\u201d and celebrating new model uploads have created a vibrant and inclusive atmosphere where inside jokes, model memes, and helpful tips circulate freely.\"\r\n\r\n-- https://aiexpert.network/hugging-face/\r\n\r\nYou can conveniently deploy and use Apertus and other published models using [Hugging Face Inference Endpoints](https://endpoints.huggingface.co/):\r\n\r\n![](https://s3.dribdat.cc/swissai/2025/1/64SIH/PW4YZ7GY.png)\r\n\r\nPartner hackathons of the Swiss {ai} Weeks can provide special access to participants. [Find the instructions here](https://zh.swiss-ai-weeks.ch/tools).\r\n\r\n![](https://camo.githubusercontent.com/37a904cb209cbc07b9b58b281dc1407e91210983491bec069b61b453d1de8ec4/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f6d7264626f75726b652f6c6561726e2d68662d696d616765732f7265736f6c76652f6d61696e2f6c6561726e2d68662d746578742d636c617373696669636174696f6e2f30312d68756767696e672d666163652d776f726b666c6f772e706e67)\r\n\r\n-- [mrdbourke/learn-huggingface](https://github.com/mrdbourke/learn-huggingface?tab=readme-ov-file)\r\n\r\nList of spaces based on Swiss data:\r\n\r\n- https://huggingface.co/spaces/albertstudy/swiss_law_gemini\r\n- https://huggingface.co/spaces/222dunja/SWX-Trading-Assistant\r\n- https://huggingface.co/spaces/umaiku/agent_RAG\r\n- https://huggingface.co/spaces/blaxe191/hiking-assistant-rag\r\n- https://huggingface.co/spaces/supertype3/my_first_agent\r\n- https://huggingface.co/spaces/kleemyan/apartments_yanic","maintainer":"","name":"Hugging Face","phase":"Project","progress":5,"score":18,"source_url":"","stats":{"commits":0,"during":4,"people":0,"sizepitch":1798,"sizetotal":1907,"total":4,"updates":2},"summary":"Share your Spaces, Datasets and Models in the world's largest model zoo, official partner of Swiss {ai} Weeks","team":"","team_count":0,"updated_at":"2025-09-19T07:16","url":"https://swissai.dribdat.cc/project/28","webpage_url":""},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"mailto:molina@begasoft.ch","created_at":"2025-09-16T07:19","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"We are on site and provide support with access to the AI orchestration platform Brandbot and the open source model Apertus.","hashtag":"BEGASOFT AG","id":65,"ident":"","image_url":"https://s3.dribdat.cc/swissai/2025/1/6V4VC/IT6AV236.png","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"We are on site and provide support with access to the AI orchestration platform Brandbot and the open source model Apertus.","maintainer":"Tomvona","name":"Brandbot ","phase":"Project","progress":5,"score":17,"source_url":"","stats":{"commits":0,"during":10,"people":0,"sizepitch":123,"sizetotal":156,"total":10,"updates":10},"summary":"AI-Platform - powered by BEGASOFT","team":"Tomvona","team_count":0,"updated_at":"2025-09-19T07:16","url":"https://swissai.dribdat.cc/project/65","webpage_url":"https://brandbot.ch/"},{"autotext":"# ForecastBench\n\n[![ICLR 2025](https://img.shields.io/badge/ICLR-2025-D5FFC1?labelColor=2A363F)](https://iclr.cc/virtual/2025/poster/28507) [![arXiv:2409.19839](https://img.shields.io/badge/arXiv-2409.19839-272727?logo=arxiv&labelColor=B31B1B)](https://arxiv.org/abs/2409.19839)\n\nA dynamic, continuously-updated benchmark to evaluate LLM forecasting capabilities. More at [www.forecastbench.org](https://www.forecastbench.org/).\n\n## Datasets\n\nLeaderboards and datasets are updated nightly and available at [github.com/forecastingresearch/forecastbench-datasets](https://github.com/forecastingresearch/forecastbench-datasets).\n\n## Participate in the benchmark\n\nInstructions for how to submit your model to the benchmark can be found here: [How-to-submit-to-ForecastBench](https://github.com/forecastingresearch/forecastbench/wiki/How-to-submit-to-ForecastBench).\n\n## Wiki\n\nDig into the details of ForecastBench on the [wiki](https://github.com/forecastingresearch/forecastbench/wiki/).\n\n## Citation\n\n```bibtex\n@inproceedings{karger2025forecastbench,\n      title={ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities},\n      author={Ezra Karger and Houtan Bastani and Chen Yueh-Han and Zachary Jacobs and Danny Halawi and Fred Zhang and Philip E. Tetlock},\n      year={2025},\n      booktitle={International Conference on Learning Representations (ICLR)},\n      url={https://iclr.cc/virtual/2025/poster/28507}\n}\n```\n\n## Getting started for devs\n\n#### Local setup\n1. `git clone --recurse-submodules <repo-url>.git`\n1. `cd forecastbench`\n1. `cp variables.example.mk variables.mk` and set the values accordingly\n1. Setup your Python virtual environment\n   1. `make setup-python-env`\n   1. `source .venv/bin/activate`\n\n#### Run GCP Cloud Functions locally\n1. `cd directory/containing/cloud/function`\n1. `eval $(cat path/to/variables.mk | xargs) python main.py`\n\n#### Contributions\n\nBefore creating a pull request:\n* run `make lint` and fix any errors and warnings\n* ensure code has been deployed to Google Cloud Platform and tested (only for our devs, for others,\n  we're happy you're contributing and we'll test this on our end).\n* fork the repo\n* reference the issue number (if one exists) in the commit message\n* push to the fork on a branch other than `main`\n* create a pull request\n","autotext_url":"https://github.com/forecastingresearch/forecastbench","category_id":"","category_name":"","contact_url":"https://github.com/forecastingresearch/forecastbench/issues","created_at":"2025-07-09T23:53","download_url":"https://github.com/forecastingresearch/forecastbench/releases","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"# ForecastBench\n\n[![ICLR 2025](https://img.shields.io/badge/ICLR-2025-D5FFC1?labelColor=2A363F)](https://iclr.cc/virtual/2025/poster/28507) [![arXiv:2409.19839](https://img.shields.io/badge/arXiv-2409.19839-272727?logo=arxiv&labelColor=B31B1B)](https://arxiv.org/abs/2409.19839)\n\nA dynamic, continuously-updated benchmark to evaluate LLM forecasting capabilities. More at [www.forecastbench.org](https://www.forecastbench.org/).\n\n## Datasets\n\nLeaderboards and datasets are updated nightly and availab...","hashtag":"","id":22,"ident":"","image_url":"https://avatars.githubusercontent.com/u/129176492?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"","maintainer":"loleg","name":"ForecastBench","phase":"Research","progress":10,"score":14,"source_url":"https://github.com/forecastingresearch/forecastbench","stats":{"commits":12,"during":13,"people":0,"sizepitch":0,"sizetotal":2350,"total":13,"updates":13},"summary":"A dynamic, continuously-updated forecasting LLM Benchmark","team":"loleg","team_count":0,"updated_at":"2025-07-09T23:54","url":"https://swissai.dribdat.cc/project/22","webpage_url":"https://www.forecastbench.org"},{"autotext":"","autotext_url":"https://github.com/compl-ai/compl-ai","category_id":"","category_name":"","contact_url":"https://github.com/compl-ai/compl-ai/issues","created_at":"2025-08-15T13:51","download_url":"https://compl-ai.org/#evaluate","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"","hashtag":"","id":39,"ident":"","image_url":"https://avatars.githubusercontent.com/u/184132995?v=4","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"","maintainer":"loleg","name":"compl-ai","phase":"Research","progress":10,"score":14,"source_url":"https://github.com/compl-ai/compl-ai","stats":{"commits":0,"during":1,"people":0,"sizepitch":0,"sizetotal":80,"total":1,"updates":0},"summary":"An open-source compliance-centered evaluation framework for Generative AI models","team":"loleg","team_count":0,"updated_at":"2025-08-15T13:52","url":"https://swissai.dribdat.cc/project/39","webpage_url":"https://compl-ai.org"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2025-08-19T14:43","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"Digital Marketplace: [digital.swisscom.com](https://digital.swisscom.com/) ~ [T&Cs](https://digital.swisscom.com/static/download/DM-TermsAndConditions-2023.pdf)\r\n\r\n## [Quickstart for hackathon access to Swiss AI Platform](https://zh.swiss-ai-weeks.ch/tools/swiss-ai-platform-quickstart-guide)\r\n\r\nSee also [Tools for Swiss {ai} Weeks Hackathons](https://zh.swiss-ai-weeks.ch/tools)\r\n","hashtag":"","id":42,"ident":"","image_url":"https://docs.cloud.swisscom.ch/logo.png","is_challenge":false,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"Digital Marketplace: [digital.swisscom.com](https://digital.swisscom.com/) ~ [T&Cs](https://digital.swisscom.com/static/download/DM-TermsAndConditions-2023.pdf)\r\n\r\n## [Quickstart for hackathon access to Swiss AI Platform](https://zh.swiss-ai-weeks.ch/tools/swiss-ai-platform-quickstart-guide)\r\n\r\nSee also [Tools for Swiss {ai} Weeks Hackathons](https://zh.swiss-ai-weeks.ch/tools)\r\n","maintainer":"loleg","name":"Swiss AI Platform","phase":"Project","progress":5,"score":13,"source_url":"","stats":{"commits":0,"during":3,"people":0,"sizepitch":380,"sizetotal":434,"total":3,"updates":3},"summary":"Enterprise-level support for AI services from Swisscom","team":"loleg","team_count":0,"updated_at":"2025-09-19T07:16","url":"https://swissai.dribdat.cc/project/42","webpage_url":"https://docs.cloud.swisscom.ch/guide/cloud-services/aip/overview/"},{"autotext":"# Apertus\r\n\r\n![image/jpeg](https://cdn-uploads.huggingface.co/production/uploads/6639f08490b7db8dcbf1a2aa/YKux3SpTciL4O60L3Ol-6.jpeg)\r\n\r\n##  Table of Contents\r\n\r\n1. [Model Summary](#model-summary)\r\n2. [How to use](#how-to-use)\r\n3. [Evaluation](#evaluation)\r\n4. [Training](#training)\r\n5. [Limitations](#limitations)\r\n6. [Legal Aspects](#legal-aspects)\r\n\r\n## Model Summary\r\n\r\nApertus is a 70B and 8B parameter language model designed to push the boundaries of fully-open multilingual and transparent models. \r\nThe model supports over 1000 languages and long context, it uses only fully compliant and open training data, and achieves comparable performance to models trained behind closed doors.\r\n\r\n![image/png](https://cdn-uploads.huggingface.co/production/uploads/654baf61d625e083383dfd00/gKDv_6dpIpvmgyquenbXt.png)\r\n\r\nThe model is a decoder-only transformer, pretrained on 15T tokens with a staged curriculum of web, code and math data. The model uses a new xIELU activation function and is trained from scratch with the AdEMAMix optimizer. Post-training included supervised fine-tuning and alignment via QRPO.\r\n\r\n### Key features\r\n- **Fully open model**: open weights + open data + full training details including all data and training recipes\r\n- **Massively Multilingual**: 1811 natively supported languages\r\n- **Compliant** Apertus is trained while respecting opt-out consent of data owners (even retrospectivey), and avoiding memorization of training data\r\n\r\nFor more details refer to our [technical report](https://github.com/swiss-ai/apertus-tech-report/blob/main/Apertus_Tech_Report.pdf)\r\n\r\n## How to use\r\n\r\nThe modeling code for Apertus is available in transformers `v4.56.0`, so make sure to upgrade your transformers version. You can also load the model with the latest `vLLM` which uses transformers as a backend.\r\n```bash\r\npip install -U transformers\r\n```\r\n\r\n```python\r\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\r\n\r\nmodel_name = \"swiss-ai/Apertus-70B-Instruct-2509\"\r\ndevice = \"cuda\"  # for GPU usage or \"cpu\" for CPU usage\r\n\r\n# load the tokenizer and the model\r\ntokenizer = AutoTokenizer.from_pretrained(model_name)\r\nmodel = AutoModelForCausalLM.from_pretrained(\r\n    model_name,\r\n).to(device)\r\n\r\n# prepare the model input\r\nprompt = \"Give me a brief explanation of gravity in simple terms.\"\r\nmessages_think = [\r\n    {\"role\": \"user\", \"content\": prompt}\r\n]\r\n\r\ntext = tokenizer.apply_chat_template(\r\n    messages_think,\r\n    tokenize=False,\r\n    add_generation_prompt=True,\r\n)\r\nmodel_inputs = tokenizer([text], return_tensors=\"pt\", add_special_tokens=False).to(model.device)\r\n\r\n# Generate the output\r\ngenerated_ids = model.generate(**model_inputs, max_new_tokens=32768)\r\n\r\n# Get and decode the output\r\noutput_ids = generated_ids[0][len(model_inputs.input_ids[0]) :]\r\nprint(tokenizer.decode(output_ids, skip_special_tokens=True))\r\n```\r\n\r\n>[!TIP]\r\n> We recommend setting `temperature=0.8` and `top_p=0.9` in the sampling parameters.\r\n\r\n### Long context processing\r\n\r\nApertus by default supports a context length up to 65,536 tokens.\r\n\r\n### Agentic Usage\r\n\r\nApertus supports tool use\r\n\r\n### Deployment\r\n\r\nDeployment of the models is directly supported by the newest versions of [Transformers](https://github.com/huggingface/transformers), [vLLM](https://github.com/vllm-project/vllm), [SGLang](https://github.com/sgl-project/sglang), and also for running on-device with [MLX](https://github.com/ml-explore/mlx-lm), \r\n\r\n## Evaluation\r\n\r\n**Pretraining Evaluation:** Performance (%) of Apertus models on *general language understanding* tasks (higher is better) compared to other pretrained models.\r\n\r\n| **Model** | **Avg** | **ARC** | **HellaSwag** | **WinoGrande** | **XNLI** | **XCOPA** | **PIQA** |\r\n| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\r\n| **Fully Open Models** | | | | | | | |\r\n| **Apertus-8B** | 65.8 | 72.7 | 59.8 | 70.6 | 45.2 | 66.5 | 79.8 |\r\n| **Apertus-70B** | 67.5 | 70.6 | 64.0 | 73.3 | 45.3 | 69.8 | 81.9 |\r\n| OLMo2-7B | 64.0 | 72.9 | 60.4 | 74.5 | 40.4 | 55.2 | 80.9 |\r\n| OLMo2-32B | 67.7 | 76.2 | 66.7 | 78.6 | 42.9 | 60.1 | 82.1 |\r\n| EuroLLM-1.7B | 54.8 | 57.2 | 44.9 | 58.1 | 40.7 | 55.7 | 72.4 |\r\n| EuroLLM-9B | 62.8 | 67.9 | 57.9 | 68.8 | 41.5 | 61.1 | 79.6 |\r\n| SmolLM2-1.7B | 58.5 | 66.1 | 52.4 | 65.6 | 37.6 | 52.3 | 77.0 |\r\n| SmolLM3-3B | 61.6 | 68.6 | 56.4 | 68.1 | 40.5 | 58.2 | 77.7 |\r\n| Poro-34B | 61.7 | 65.7 | 57.9 | 70.6 | 41.6 | 56.0 | 78.5 |\r\n| **Open-Weight Models** | | | | | | | |\r\n| Llama3.1-8B | 65.4 | 71.6 | 60.0 | 73.4 | 45.3 | 61.8 | 80.1 |\r\n| Llama3.1-70B | 67.3 | 74.4 | 56.5 | 79.4 | 44.3 | 66.7 | 82.3 |\r\n| Qwen2.5-7B | 64.4 | 69.6 | 60.1 | 72.8 | 43.3 | 61.7 | 78.7 |\r\n| Qwen2.5-72B | 69.8 | 76.2 | 67.5 | 78.0 | 46.9 | 68.2 | 82.0 |\r\n| Qwen3-32B | 67.8 | 75.6 | 64.0 | 73.8 | 44.4 | 67.9 | 80.9 |\r\n| Llama4-Scout-16x17B | 67.9 | 74.7 | 66.8 | 73.2 | 43.5 | 67.7 | 81.2 |\r\n| GPT-OSS-20B | 58.1 | 67.0 | 41.5 | 66.5 | 37.4 | 60.4 | 75.6 |\r\n\r\nMany additional benchmark evaluations, for pretraining and posttraining phases, multilingual evaluations in around hundred languages, and long context evaluations are provided in Section 5 of the [Apertus_Tech_Report.pdf](https://github.com/swiss-ai/apertus-tech-report/blob/main/Apertus_Tech_Report.pdf)\r\n\r\n## Training\r\n\r\n### Model\r\n\r\n- **Architecture:** Transformer decoder\r\n- **Pretraining tokens:** 15T\r\n- **Precision:** bfloat16\r\n\r\n### Software & hardware\r\n\r\n- **GPUs:** 4096 GH200\r\n- **Training Framework:** [Megatron-LM](https://github.com/swiss-ai/Megatron-LM)\r\n- ...\r\n\r\n### Open resources\r\nAll elements used in the training process are made openly available\r\n- **Training data reconstruction scripts:** [github.com/swiss-ai/pretrain-data](https://github.com/swiss-ai/pretrain-data)\r\n- The training intermediate checkpoints are available on the different branches of this same repository\r\n\r\n\r\n## Limitations\r\n\r\nApertus can produce text on a variety of topics, but the generated content may not always be factually accurate, logically consistent, or free from biases present in the training data. These models should be used as assistive tools rather than definitive sources of information. Users should always verify important information and critically evaluate any generated content.\r\n\r\n\r\n## Legal Aspects\r\n\r\n#### EU AI Act Transparency Documentation and Code of Practice\r\n- [Apertus_EU_Public_Summary.pdf](https://huggingface.co/swiss-ai/Apertus-70B-2509/blob/main/Apertus_EU_Public_Summary.pdf)\r\n- [Apertus_EU_Code_of_Practice.pdf](https://huggingface.co/swiss-ai/Apertus-70B-2509/blob/main/Apertus_EU_Code_of_Practice.pdf)\r\n\r\n#### Data Protection and Copyright Requests\r\nFor removal requests of personally identifiable information (PII) or of copyrighted content, please contact the respective dataset owners or us directly\r\n- llm-privacy-requests@swiss-ai.org\r\n- llm-copyright-requests@swiss-ai.org\r\n  \r\n#### Output Filter for PII\r\n- Currently no output filter is provided.\r\n- Please check this site regularly for an output filter that can be used on top of the Apertus LLM. The filter reflects data protection deletion requests which have been addressed to us as the developer of the Apertus LLM. It allows you to remove Personal Data contained in the model output. We strongly advise downloading and applying this output filter from this site every six months.\r\n\r\n## Contact\r\nTo contact us, please send an email to\r\nllm-requests@swiss-ai.org\r\n\r\n## Citation\r\n```bash\r\n@misc{swissai2025apertus,\r\n  title={{Apertus: Democratizing Open and Compliant LLMs for Global Language Environments}},\r\n  author={Apertus Team},\r\n  year={2025},\r\n  howpublished={\\url{https://huggingface.co/swiss-ai/Apertus-70B-2509}}\r\n}\r\n```","autotext_url":"https://huggingface.co/swiss-ai/Apertus-70B-Instruct-2509","category_id":"","category_name":"","contact_url":"","created_at":"2025-08-15T14:07","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"# An LLM built for the public good\r\n\r\nA Large Language Model will be launched in time for Swiss {ai} Weeks 2025, developed by ETH Zurich, EPFL, CERN, CSCS and many other contributors and sources. The project focuses on transparency, data privacy, and linguistic diversity. It will not initially be multi-modal or interchangeable with existing models. Nevertheless it will be an advanced product with unique features. We will try to gather details here as they are made available.\r\n\r\n_Thanks to Michae...","hashtag":"","id":40,"ident":"","image_url":"https://static.wixstatic.com/media/50d73a_6a2c8add986f4adbae8bdd9e4bc19f53~mv2.jpg/v1/fill/w_278,h_278,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/Swiss%20Key%20Visual.jpg","is_challenge":true,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"# An LLM built for the public good\r\n\r\nA Large Language Model will be launched in time for Swiss {ai} Weeks 2025, developed by ETH Zurich, EPFL, CERN, CSCS and many other contributors and sources. The project focuses on transparency, data privacy, and linguistic diversity. It will not initially be multi-modal or interchangeable with existing models. Nevertheless it will be an advanced product with unique features. We will try to gather details here as they are made available.\r\n\r\n_Thanks to Michael J. Baumann ([effektiv.ch](https://www.effektiv.ch/en/blog/swiss-llm)) for the summary and charts that are adapted further below._\r\n\r\n[![Technical Report](https://s3.dribdat.cc/swissai/2025/1/IUL5A/7B8GVK6E.png)](https://github.com/swiss-ai/apertus-tech-report/blob/main/Apertus_Tech_Report.pdf)\r\n\r\n## Key characteristics\r\n\r\nThe model is part of the [Swiss AI Initiative](https://www.swiss-ai.org/), which started in late 2023. This is a platform for over 80 data science projects including the LLM development. \r\n\r\nKey highlights of the LLM project, as [announced in July](https://ethz.ch/en/news-and-events/eth-news/news/2025/07/a-language-model-built-for-the-public-good.html):\r\n\r\n-   **Multilingualism**: Trained on more than 15 trillion tokens across 1,500+ languages, 40% non-English - equal usage cost across languages - see [@epfml](http://huggingface.co/datasets/epfml)\r\n-   **Performance**: This is a large model (8 billion and 70 billion parameters), trained on a lot of tokens, and it will be continue to be actively optimized.\r\n-   **Open & Transparent**: Published under Apache-2.0 license - including source code, weights, and open training data.\r\n-   **Data Privacy**: Compliant with GDPR, EU AI Act, and Swiss data protection laws - see [Fan et al 2025](https://arxiv.org/abs/2504.06219)\r\n-   **Infrastructure**: Developed on the new Alps supercomputer at CSCS with over 10,000 NVIDIA GH200 Grace-Hopper chips\r\n-   **Global Reach**: Research and borderless applications in mind, for sovereign and international public-interest AI.\r\n\r\nThe Swiss LLM project is currently led by:\r\n\r\n-   Prof. Andreas Krause (ETH Z\u00fcrich), an internationally recognized [expert in Reinforcement Learning](https://inf.ethz.ch/de/personen/person-detail.krause.html)\r\n-   Prof. Martin Jaggi (EPF Lausanne), who leads the [Machine Learning & Optimization Lab](https://www.epfl.ch/labs/mlo/)\r\n-   The [Swiss National AI Institute](https://ethz.ch/en/news-and-events/eth-news/news/2024/10/eth-zurich-and-epfl-enhance-collaboration-to-boost-ai-in-switzerland.html), developing since 2024 collaboration between research and applications\r\n\r\n## Tech specs\r\n\r\nThe Swiss LLM is trained on the [Alps supercomputer](https://en.wikipedia.org/wiki/Alps_(supercomputer)), operational at CSCS since [September 2024](https://www.netzwoche.ch/news/2024-09-17/neue-forschungsinfrastruktur-supercomputer-alps-eingeweiht):\r\n\r\n-   10,752 NVIDIA GH200 Grace-Hopper chips\r\n-   Computing power: 270-435 PFLOPS\r\n-   [Ranked 6th on the TOP500 list](https://top500.org/lists/top500/2024/06/) (June 2024)\r\n\r\nThe Swiss LLM was trained on approximately 15 trillion tokens. Particularly noteworthy is the high proportion of non-English data (40%) and coverage of over 1,500 languages, including rare ones like Romansh or Zulu. The data was ethically sourced - without illegal scraping, respecting `robots.txt` and copyright requirements. While this limits access to certain specialized information, CSCS emphasizes: \u00abFor general tasks, this doesn't lead to measurable performance losses.\u00bb\r\n\r\nFor more technical references, see the links below.\r\n\r\n### Initial benchmarks\r\n\r\nSee the [Evaluation section](https://huggingface.co/swiss-ai/Apertus-8B-2509#evaluation) of the Apertus Model Card, and Section 5 of the [Tech Report](https://github.com/swiss-ai/apertus-tech-report/blob/main/Apertus_Tech_Report.pdf) for more data. This is an initial independent evaluation, and we expect more to come soon: \r\n\r\n| Model | MMLU (Knowledge) | Global-MMLU (Multilingual) | GSM8K (Math) | HumanEval (Code) | RULER @32k (Long Context) |\r\n| --- | --- | --- | --- | --- | --- |\r\n| Claude 3.5 Sonnet | 88.7% | \u2014   | 96.4% | 92.0% | \u2014   |\r\n| Llama 3.1 70B | 83.6% | \u2014   | 95.1% | 80.5% | \u2014   |\r\n| Apertus-70B | 69.6% | 62.7% | 77.6% | 73.0% | 80.6% |\r\n| Apertus-8B | 60.9% | 55.7% | 62.9% | 67.0% | 69.5% |\r\n\r\n> \"Notes on Comparability: The prompt setups differ between models (shot numbers and chain-of-thought configurations). Global-MMLU and RULER values are not available in the official documentation for the comparison models. The 70B variant convinces in general knowledge and multilingual tasks, but remains behind the top models in mathematics and programming.\"\r\n\r\nSource: [effektiv.ch](https://www.effektiv.ch/en/blog/apertus-release), [lifearchitect.ai](https://lifearchitect.ai/models-table/)\r\n\r\n## Performance comparison\r\n\r\n| Model | Parameters | Openness | Language Coverage | Training Hardware | Strengths |\r\n| --- | --- | --- | --- | --- | --- |\r\n| Swiss LLM | 8B / 70B | Open Source, Weights, Data | >1,500 | Alps: 10,752 GH200 GPUs | Linguistic diversity, data privacy, transparency |\r\n| GPT-4.5 | ~2T (estimated) | Proprietary | ~80 - 120 | Azure: ~25,000 A100 GPUs | Creativity, natural conversation, agentic planning |\r\n| Claude 4 | Not published | Proprietary | ? | Anthropic: Internal clusters | Adaptive reasoning, coding |\r\n| Llama 4 | 109B / 400B | Open Weight | 12, with 200+ in training | Meta: ~20,000 H100 GPUs | Multimodality, large community, agentic tasks |\r\n| Grok 4 | ~1.8T MoE | Proprietary | ? | Colossus: 200,000 H100 GPUs | Reasoning, real-time data, humor... |\r\n\r\nSource: [effektiv.ch](https://www.effektiv.ch/en/blog/swiss-llm)\r\n\r\n## Sources\r\n\r\n\ud83d\udca1 Find links to tools and benchmarks in our [Resources area](https://swissai.dribdat.cc/event/2)\r\n\r\nFor further information:\r\n\r\n- [Swiss AI Initiative](https://www.swiss-ai.org/) (swiss-ai.org)\r\n- [July Announcement](https://ethz.ch/en/news-and-events/eth-news/news/2025/07/a-language-model-built-for-the-public-good.html) (ethz.ch)\r\n- [ETH Zurich AI Center](https://ai.ethz.ch/) (ai.ethz.ch)\r\n- [EPFL Machine Learning Lab](https://www.epfl.ch/labs/mlo/) (epfl.ch)\r\n- [Can the Swiss LLM Compete?](https://www.effektiv.ch/en/blog/swiss-llm) (effektiv.ch)\r\n- [AlgorithmWatch statement](https://algorithmwatch.ch/de/apartus-eth-epfl/) & [position paper](https://algorithmwatch.ch/en/ai-regulation/)\r\n- [Alps Supercomputer ranking](https://top500.org/lists/top500/2024/06/) (TOP500.org)\r\n- [Modern Transformer Design Guide](https://rohitbandaru.github.io/blog/Transformer-Design-Guide-Pt2/) (Rohit Bandaru) \r\n- [GLU Variants Improve Transformer](https://arxiv.org/abs/2002.05202) (Shazeer 2020)\r\n","maintainer":"loleg","name":"Apertus","phase":"Challenge","progress":0,"score":0,"source_url":"","stats":{"commits":0,"during":11,"people":0,"sizepitch":6720,"sizetotal":14448,"total":11,"updates":6},"summary":"Learn about the new foundation model from the Swiss AI Initiative.","team":"loleg","team_count":0,"updated_at":"2025-09-10T22:06","url":"https://swissai.dribdat.cc/project/40","webpage_url":"https://drive.google.com/file/d/1NYiK648rdX0ypRSfcIcSdnL36suGh9ce/preview"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2025-05-08T08:32","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"Visit https://data-hackdays-be.ch for more information.","hashtag":"","id":3,"ident":"","image_url":"https://data-hackdays-be.ch/content/images/size/w256h256/2022/12/Grafik-Final-DE_icon-3.png","is_challenge":true,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"Visit https://data-hackdays-be.ch for more information.","maintainer":"loleg","name":"Data Hackdays BE","phase":"Challenge","progress":0,"score":0,"source_url":"","stats":{"commits":0,"during":2,"people":0,"sizepitch":55,"sizetotal":146,"total":7,"updates":6},"summary":"Pick up ideas, get data, continue a project from previous hackathons of the Canton of Bern.","team":"loleg","team_count":0,"updated_at":"2025-09-08T09:28","url":"https://swissai.dribdat.cc/project/3","webpage_url":"https://app.data-hackdays-be.ch/?&hexagons=1&previews=1&comments=1&dark=light&sort=ident"},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2025-08-12T14:19","download_url":"https://swiss-ai-weeks.ch/challenges","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"See also [Tools for Swiss {ai} Weeks Hackathons](https://zh.swiss-ai-weeks.ch/tools)","hashtag":"","id":36,"ident":"","image_url":"https://swiss-ai-weeks.ch/logos/swiss-ai-icon.png","is_challenge":true,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"See also [Tools for Swiss {ai} Weeks Hackathons](https://zh.swiss-ai-weeks.ch/tools)","maintainer":"","name":"Hackathon Zurich","phase":"Challenge","progress":0,"score":0,"source_url":"","stats":{"commits":0,"during":1,"people":0,"sizepitch":84,"sizetotal":198,"total":1,"updates":1},"summary":"Take on real-world AI challenges from Switzerland's leading companies at the Swiss {ai} Weeks Hackathon in Zurich.","team":"","team_count":0,"updated_at":"2025-09-08T09:29","url":"https://swissai.dribdat.cc/project/36","webpage_url":"https://zh.swiss-ai-weeks.ch/challenges"},{"autotext":"![logo](https://raw.githubusercontent.com/LauzHack/deep-learning-bootcamp/summer25/docs/logo.png)\r\n\r\n# Deep Learning Bootcamp\r\n\r\nSince 2016, LauzHack has organized hackathons at EPFL in Lausanne, Switzerland. We also organize tech talks during the school year.\r\n\r\nThis is a repository for our Deep Learning Bootcamp (Summer 2025 Edition). For previous editions, see [Previous Editions](#previous-editions) section.\r\n\r\n# Syllabus\r\n\r\n- [**day01**](./day01) Introduction to Deep Learning and PyTorch\r\n  - Lecture: Introduction to bootcamp and Deep Learning\r\n  - Seminar: Introduction to `pytorch`\r\n- [**day02**](./day02) Basic Model Architectures\r\n  - Lecture: Fully-connected and Convolutional Neural Networks, ResNet\r\n  - Seminar: Models in `pytorch` and training pipeline\r\n- [**day03**](./day03) Recurrent Neural Networks\r\n  - Lecture: Recurrent Neural Networks, LSTM, GRU\r\n  - Seminar: RNN, LSTM, GRU example\r\n- [**day04**](./day04) Transformer and Normalization layers. Introduction to NLP.\r\n  - Lecture: Transformer. BatchNorm, LayerNorm.\r\n  - Seminar: Implementation of Transformer in `pytorch`\r\n- [**day05**](./day05) Creating convenient Deep Learning pipelines and clean reproducible code.\r\n  - Lecture: Logging, Configuration, Reproducibility, and Project-based code development.\r\n- [**day06**](./day06) Large Language Models (LLMs) and Brain-inspired LLMs.\r\n  - Lecture: Introduction to LLMs and how can we improve them through brain-inspiration.\r\n- [**day07**](./day07) Multimodal deep learning and deep learning for audio.\r\n  - Lecture: Introduction to audio domain. Multimodality and Generative AI. Deepfakes.\r\n  - Seminar: Basics of audio processing. Keyword-spotting task implementation.\r\n- [**day08**](./day08) Source Separation and Deepfake Detection.\r\n  - Lecture 1: Diffusion models, Source Separation\r\n  - Lecture 2: Deepfake Detection, Self-Supervised Models, Graph Neural Networks\r\n  - Seminar 2: Audio anti-spoofing, Graph Neural Networks implementation.\r\n\r\n<!--\r\n  -->\r\n\r\nFor self-practice, we also propose several [Projects](PROJECTS.md).\r\n\r\n# Resources\r\n\r\n- [Recordings on YouTube](https://youtube.com/playlist?list=PLpYenI2Zwc7anzzqCBj8KJkyny0xAaUKC)\r\n\r\n# Contributors & bootcamp staff\r\n\r\nBootcamp materials and teaching were delivered by:\r\n\r\n- Petr Grinberg\r\n- Seyed Parsa Neshaei\r\n- Badr AlKhamissi\r\n- Mingchi (Alina) Hou\r\n- Eric Bezzam (Previously)\r\n- Ali Hariri (Previously)\r\n- Nikita Durasov (Previously)\r\n- Federico Stella (Previously)\r\n- Atli Kosson (Previously)\r\n- Cristian Cioflan (Previously)\r\n- Skander Moalla (Previously)\r\n- Vinitra Swamy (Previously)\r\n\r\n# Previous Editions\r\n\r\n- [Winter 2025](https://github.com/LauzHack/deep-learning-bootcamp/tree/winter25/)\r\n- [Summer 2024](https://github.com/LauzHack/deep-learning-bootcamp/tree/summer24/)\r\n","autotext_url":"https://github.com/LauzHack/deep-learning-bootcamp","category_id":"","category_name":"","contact_url":"https://github.com/LauzHack/deep-learning-bootcamp/issues","created_at":"2025-08-11T20:45","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"https://www.youtube.com/watch?v=PE1zaW5it_A\r\n\r\nSee also:\r\n\r\n* [Swiss {ai} Weeks - Lausanne](https://luma.com/swissai-lausanne)\r\n* [LauzHack 2025 - November 22-23 at EPFL](https://lauzhack.com/) \r\n* [Mini-hackathon on Multimodal Apps and Training LLMs](https://github.com/LauzHack/llms-api-hackathon) (GitHub)","hashtag":"","id":34,"ident":"","image_url":"https://avatars.githubusercontent.com/u/21334299?v=4","is_challenge":true,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"https://www.youtube.com/watch?v=PE1zaW5it_A\r\n\r\nSee also:\r\n\r\n* [Swiss {ai} Weeks - Lausanne](https://luma.com/swissai-lausanne)\r\n* [LauzHack 2025 - November 22-23 at EPFL](https://lauzhack.com/) \r\n* [Mini-hackathon on Multimodal Apps and Training LLMs](https://github.com/LauzHack/llms-api-hackathon) (GitHub)","maintainer":"loleg","name":"LauzHack bootcamp","phase":"Challenge","progress":0,"score":0,"source_url":"https://github.com/LauzHack/deep-learning-bootcamp","stats":{"commits":17,"during":20,"people":0,"sizepitch":308,"sizetotal":3196,"total":20,"updates":20},"summary":"A repository for the Deep Learning Bootcamp (Summer 2025 Edition) from the Lausanne hackathon organisers.","team":"loleg","team_count":0,"updated_at":"2025-09-08T09:33","url":"https://swissai.dribdat.cc/project/34","webpage_url":""},{"autotext":"","autotext_url":"","category_id":"","category_name":"","contact_url":"","created_at":"2025-09-08T10:03","download_url":"","event_name":"Resources","event_url":"https://swissai.dribdat.cc/event/2","excerpt":"We will expand this page with reports on how well Apertus works with the following software:\r\n\r\n- [Ollama](https://ollama.ai/): run Llama 2, Code Llama, and other models locally\r\n- [Jan.ai](http://jan.ai/): an open source alternative to ChatGPT that runs 100% offline on your computer.\r\n- [GPT4All](https://gpt4all.io/index.html): A free-to-use, locally running, privacy-aware chatbot. No GPU or internet is required.\r\n- [LM Studio](https://lmstudio.ai/): Discover, download, and run local LLMs.\r\n- [...","hashtag":"","id":58,"ident":"","image_url":"https://d4.alternativeto.net/wsp-3KLOco2KYZFXIsvu_53ERsrFrCP5xi_gi7621aE/rs:fit:140:140:0/g:ce:0:0/exar:1/YWJzOi8vZGlzdC9pY29ucy9qYW4tYWlfMjMzMTA1LnN2Zw.svg","is_challenge":true,"is_webembed":false,"logo_color":"","logo_icon":"","longtext":"We will expand this page with reports on how well Apertus works with the following software:\r\n\r\n- [Ollama](https://ollama.ai/): run Llama 2, Code Llama, and other models locally\r\n- [Jan.ai](http://jan.ai/): an open source alternative to ChatGPT that runs 100% offline on your computer.\r\n- [GPT4All](https://gpt4all.io/index.html): A free-to-use, locally running, privacy-aware chatbot. No GPU or internet is required.\r\n- [LM Studio](https://lmstudio.ai/): Discover, download, and run local LLMs.\r\n- [PowerInfer](https://github.com/SJTU-IPADS/PowerInfer): a high-speed inference engine for deploying LLMs locally.\r\n- [llama.cpp guide](https://steelph0enix.github.io/posts/llama-cpp-guide/): Running LLMs locally, on any hardware, from scratch.\r\n\r\nFeel free to add your own! See also: \r\n\r\n- [AlternativeTo: Open source LLMs](https://alternativeto.net/feature/large-language-models/?license=opensource)\r\n- https://github.com/abordage/awesome-ai\r\n- https://github.com/filipecalegario/awesome-generative-ai","maintainer":"loleg","name":"Open LLM tools","phase":"Challenge","progress":0,"score":0,"source_url":"","stats":{"commits":0,"during":1,"people":0,"sizepitch":1001,"sizetotal":1056,"total":1,"updates":1},"summary":"To run Apertus or another model on a desktop or server.","team":"loleg","team_count":0,"updated_at":"2025-09-09T08:56","url":"https://swissai.dribdat.cc/project/58","webpage_url":""}],"name":"projects"}],"sources":[{"path":"https://swissai.dribdat.cc/","title":"dribdat"}],"title":"Resources","version":"0.9.2"}
